#!/usr/bin/env python3
"""
SAP S/4HANA Data Quality Logging & Reporting Service
Provides web dashboard, REST API, and reporting functionality
"""

import os
import json
import logging
import sys
import requests
import uuid
from datetime import datetime, timedelta
def _to_json_safe(value):
    """Recursively convert datetimes and non-serializable objects to JSON-safe forms."""
    if isinstance(value, datetime):
        return value.isoformat()
    if isinstance(value, dict):
        return {k: _to_json_safe(v) for k, v in value.items()}
    if isinstance(value, (list, tuple)):
        return [_to_json_safe(v) for v in value]
    try:
        json.dumps(value)
        return value
    except Exception:
        return str(value)
from typing import Dict, List, Optional, Any
from pathlib import Path

import pandas as pd
import numpy as np
import requests
from flask import Flask, request, jsonify, render_template, send_file, session, redirect, url_for, flash, g
from flask_cors import CORS
from flask_wtf.csrf import CSRFProtect
from flask_restful import Api, Resource
from flask_login import LoginManager, login_user, logout_user, login_required, current_user, UserMixin
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
import structlog
from sqlalchemy import create_engine, text, func
import plotly.graph_objs as go
import plotly.utils
from io import BytesIO
import openpyxl
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph
from reportlab.lib.styles import getSampleStyleSheet
import psycopg2

# Import authentication modules
from models import User, AuditLog, SecurityEvent
from auth import AuthService

# Import additional security modules
import re
import hashlib
import base64
from functools import wraps
from datetime import datetime, timedelta
import json

# Import caching and load balancing modules
import redis
from functools import lru_cache
import threading
import time

# Import vector service for AI context
from vector_service import VectorService

# Import AI agents
from ai_agents import AIAgentManager, AgentConfig

# Configure structured logging (standard fields across services)
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger(service="logging-service")

# Also set up regular logging for debugging
logging.basicConfig(level=logging.INFO, stream=sys.stderr)

app = Flask(__name__)

# SECRET_KEY from Docker secret or env; do not hardcode
def _read_secret(path_env: str, fallback_env: str) -> str:
    path = os.getenv(path_env)
    if path and os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f:
            return f.read().strip()
    return os.getenv(fallback_env, '')

_secret = _read_secret('SECRET_KEY_FILE', 'SECRET_KEY')
if not _secret:
    raise RuntimeError('SECRET_KEY not provided. Set SECRET_KEY or mount SECRET_KEY_FILE')
app.secret_key = _secret

# Secure session cookies
_secure_cookie = str(os.getenv('SESSION_COOKIE_SECURE', 'false')).lower() in ('1', 'true', 'yes')
app.config.update(
    SESSION_COOKIE_SECURE=_secure_cookie,
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SAMESITE=os.getenv('SESSION_COOKIE_SAMESITE', 'Lax'),
    PERMANENT_SESSION_LIFETIME=timedelta(hours=int(os.getenv('SESSION_LIFETIME_HOURS', '8'))),
)

# Initialize Flask extensions
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'login'

# CSRF disabled for MVP
csrf = None

# Configure rate limiting (defaults can be overridden via env)
DEFAULT_RATE_LIMIT = os.getenv('DEFAULT_RATE_LIMIT', '60/minute')
limiter = Limiter(app=app, key_func=get_remote_address, default_limits=[DEFAULT_RATE_LIMIT])

# Restrictive CORS: enable only if CORS_ORIGINS set
_cors_origins = [o.strip() for o in os.getenv('CORS_ORIGINS', '').split(',') if o.strip()]
if _cors_origins:
    CORS(app, resources={r"/api/*": {"origins": _cors_origins}})
api = Api(app)

# Prometheus metrics
REQUEST_COUNT = Counter('logging_service_requests_total', 'Total requests', ['endpoint'])
REQUEST_LATENCY = Histogram('logging_service_request_duration_seconds', 'Request latency')
REPORT_GENERATION_COUNT = Counter('logging_service_reports_generated_total', 'Reports generated', ['report_type'])
SERVICE_READY = Gauge('logging_service_ready', 'Readiness status (1=ready, 0=not_ready)')
ERROR_COUNT = Counter('logging_service_errors_total', 'Unhandled exceptions')

# Initialize authentication service
auth_service = None

# Caching Configuration
CACHE_CONFIG = {
    'redis_host': os.getenv('REDIS_HOST', 'redis'),
    'redis_port': int(os.getenv('REDIS_PORT', 6379)),
    'redis_db': int(os.getenv('REDIS_DB', 0)),
    'default_ttl': 300,  # 5 minutes
    'max_ttl': 3600,     # 1 hour
    'enabled': os.getenv('CACHE_ENABLED', 'true').lower() == 'true'
}

# Load Balancing Configuration
LOAD_BALANCER_CONFIG = {
    'enabled': os.getenv('LOAD_BALANCER_ENABLED', 'false').lower() == 'true',
    'health_check_interval': 30,  # seconds
    'max_retries': 3,
    'timeout': 10  # seconds
}

# Initialize Redis cache
redis_client = None
if CACHE_CONFIG['enabled']:
    try:
        redis_client = redis.Redis(
            host=CACHE_CONFIG['redis_host'],
            port=CACHE_CONFIG['redis_port'],
            db=CACHE_CONFIG['redis_db'],
            decode_responses=True
        )
        # Test connection
        redis_client.ping()
        logger.info("Redis cache initialized successfully")
    except Exception as e:
        logger.warning(f"Redis cache not available: {str(e)}")
        redis_client = None

def cache_get(key: str, default=None):
    """Get value from cache"""
    if not redis_client or not CACHE_CONFIG['enabled']:
        return default
    
    try:
        value = redis_client.get(key)
        return json.loads(value) if value else default
    except Exception as e:
        logger.error(f"Cache get error: {str(e)}")
        return default

def cache_set(key: str, value, ttl: int = None):
    """Set value in cache"""
    if not redis_client or not CACHE_CONFIG['enabled']:
        return False
    
    try:
        ttl = ttl or CACHE_CONFIG['default_ttl']
        redis_client.setex(key, ttl, json.dumps(value))
        return True
    except Exception as e:
        logger.error(f"Cache set error: {str(e)}")
        return False

def cache_delete(key: str):
    """Delete value from cache"""
    if not redis_client or not CACHE_CONFIG['enabled']:
        return False
    
    try:
        redis_client.delete(key)
        return True
    except Exception as e:
        logger.error(f"Cache delete error: {str(e)}")
        return False

def cache_clear_pattern(pattern: str):
    """Clear cache entries matching pattern"""
    if not redis_client or not CACHE_CONFIG['enabled']:
        return False
    
    try:
        keys = redis_client.keys(pattern)
        if keys:
            redis_client.delete(*keys)
        return True
    except Exception as e:
        logger.error(f"Cache clear pattern error: {str(e)}")
        return False

def with_cache(ttl: int = None, key_prefix: str = ''):
    """Decorator for caching function results"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # Generate cache key
            cache_key = f"{key_prefix}:{func.__name__}:{hash(str(args) + str(sorted(kwargs.items())))}"
            
            # Try to get from cache
            cached_result = cache_get(cache_key)
            if cached_result is not None:
                return cached_result
            
            # Execute function and cache result
            result = func(*args, **kwargs)
            cache_set(cache_key, result, ttl or CACHE_CONFIG['default_ttl'])
            
            return result
        return wrapper
    return decorator

# Load balancing health check
def health_check_load_balancer():
    """Health check for load balancer"""
    try:
        # Check database connection
        if auth_service:
            # Test database connection
            test_query = auth_service.execute_query("SELECT 1")
            if not test_query:
                return False
        
        # Check Redis connection
        if redis_client:
            redis_client.ping()
        
        return True
    except Exception as e:
        logger.error(f"Health check failed: {str(e)}")
        return False

# Data Masking and DLP Configuration
SENSITIVE_PATTERNS = {
    'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
    'phone': r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',
    'ssn': r'\b\d{3}-\d{2}-\d{4}\b',
    'credit_card': r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b',
    'ip_address': r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b'
}

DLP_RULES = {
    'sensitive_data_detected': {
        'severity': 'high',
        'action': 'log_and_alert',
        'description': 'Sensitive data detected in request'
    },
    'suspicious_activity': {
        'severity': 'medium',
        'action': 'log_and_monitor',
        'description': 'Suspicious activity detected'
    },
    'data_export_attempt': {
        'severity': 'medium',
        'action': 'log_and_audit',
        'description': 'Data export attempt detected'
    }
}

def mask_sensitive_data(text: str) -> str:
    """Mask sensitive data in text"""
    if not text:
        return text
    
    masked_text = text
    
    # Mask email addresses
    masked_text = re.sub(SENSITIVE_PATTERNS['email'], '[EMAIL]', masked_text)
    
    # Mask phone numbers
    masked_text = re.sub(SENSITIVE_PATTERNS['phone'], '[PHONE]', masked_text)
    
    # Mask SSN
    masked_text = re.sub(SENSITIVE_PATTERNS['ssn'], '[SSN]', masked_text)
    
    # Mask credit card numbers
    masked_text = re.sub(SENSITIVE_PATTERNS['credit_card'], '[CC]', masked_text)
    
    # Mask IP addresses (except localhost)
    def mask_ip(match):
        ip = match.group(0)
        if ip.startswith('127.') or ip.startswith('192.168.') or ip.startswith('10.'):
            return ip
        return '[IP]'
    
    masked_text = re.sub(SENSITIVE_PATTERNS['ip_address'], mask_ip, masked_text)
    
    return masked_text

def detect_sensitive_data(text: str) -> dict:
    """Detect sensitive data in text"""
    findings = {}
    
    for data_type, pattern in SENSITIVE_PATTERNS.items():
        matches = re.findall(pattern, text)
        if matches:
            findings[data_type] = {
                'count': len(matches),
                'examples': matches[:3]  # Limit examples
            }
    
    return findings

def dlp_check(data: str, context: str = 'general') -> dict:
    """Perform Data Loss Prevention check"""
    findings = detect_sensitive_data(data)
    
    if findings:
        # Log DLP event
        if auth_service:
            auth_service.log_security_event(
                event_type='dlp_violation',
                severity='high',
                source_ip=request.remote_addr if 'request' in globals() else None,
                details=f'Sensitive data detected in {context}: {findings}'
            )
    
    return {
        'violation': bool(findings),
        'findings': findings,
        'context': context
    }

def compliance_report_generator(user_id: int, report_type: str = 'security') -> dict:
    """Generate compliance reports"""
    if not auth_service:
        return {'error': 'Auth service not available'}
    
    try:
        # Get audit logs for the last 30 days
        audit_logs = auth_service.get_audit_logs(
            user_id=user_id,
            days=30
        )
        
        # Get security events for the last 30 days
        security_events = auth_service.get_security_events(
            days=30
        )
        
        # Calculate compliance metrics
        total_events = len(audit_logs) + len(security_events)
        security_events_by_severity = {}
        user_activity_summary = {}
        
        for event in security_events:
            severity = event.get('severity', 'unknown')
            security_events_by_severity[severity] = security_events_by_severity.get(severity, 0) + 1
        
        for log in audit_logs:
            action = log.get('action', 'unknown')
            user_activity_summary[action] = user_activity_summary.get(action, 0) + 1
        
        # Generate compliance score
        compliance_score = 100
        if security_events_by_severity.get('critical', 0) > 0:
            compliance_score -= 30
        if security_events_by_severity.get('high', 0) > 5:
            compliance_score -= 20
        if security_events_by_severity.get('medium', 0) > 10:
            compliance_score -= 10
        
        compliance_score = max(0, compliance_score)
        
        report = {
            'report_type': report_type,
            'generated_at': datetime.utcnow().isoformat(),
            'period_days': 30,
            'compliance_score': compliance_score,
            'total_events': total_events,
            'security_events_by_severity': security_events_by_severity,
            'user_activity_summary': user_activity_summary,
            'recommendations': []
        }
        
        # Add recommendations based on findings
        if compliance_score < 70:
            report['recommendations'].append('Implement additional security controls')
        if security_events_by_severity.get('critical', 0) > 0:
            report['recommendations'].append('Address critical security events immediately')
        if security_events_by_severity.get('high', 0) > 5:
            report['recommendations'].append('Review and address high-severity events')
        
        return report
        
    except Exception as e:
        logger.error(f"Error generating compliance report: {str(e)}")
        return {'error': 'Failed to generate compliance report'}

def enhanced_security_monitoring():
    """Enhanced security monitoring and alerting"""
    if not auth_service:
        return
    
    try:
        # Check for suspicious patterns
        recent_events = auth_service.get_security_events(hours=1)
        
        # Detect potential threats
        threats = []
        
        # Check for brute force attempts
        failed_logins = [e for e in recent_events if e.get('event_type') == 'login_failed']
        if len(failed_logins) > 10:
            threats.append({
                'type': 'brute_force_attempt',
                'severity': 'high',
                'description': f'Multiple failed login attempts detected: {len(failed_logins)}'
            })
        
        # Check for unusual data access patterns
        data_access_events = [e for e in recent_events if 'data_access' in e.get('event_type', '')]
        if len(data_access_events) > 50:
            threats.append({
                'type': 'unusual_data_access',
                'severity': 'medium',
                'description': f'Unusual data access pattern detected: {len(data_access_events)} events'
            })
        
        # Check for DLP violations
        dlp_violations = [e for e in recent_events if e.get('event_type') == 'dlp_violation']
        if dlp_violations:
            threats.append({
                'type': 'dlp_violation',
                'severity': 'high',
                'description': f'Data Loss Prevention violations detected: {len(dlp_violations)}'
            })
        
        # Log threats if detected
        for threat in threats:
            auth_service.log_security_event(
                event_type='threat_detected',
                severity=threat['severity'],
                details=threat['description']
            )
        
        return threats
        
    except Exception as e:
        logger.error(f"Error in enhanced security monitoring: {str(e)}")
        return []

@login_manager.user_loader
def load_user(user_id):
    """Load user for Flask-Login"""
    if auth_service:
        return auth_service.get_user_by_id(int(user_id))
    return None

# Security middleware
@app.before_request
def before_request():
    """Security middleware for all requests"""
    global auth_service
    
    # Initialize auth service if not already done
    if auth_service is None:
        # Use app/reporting credentials (DB_*) for AuthService
        db_host = os.getenv('DB_HOST', 'postgres')
        db_name = os.getenv('DB_NAME', 'sap_data_quality')
        db_user = os.getenv('DB_USER', 'sap_user')
        db_pw = None
        pw_path = os.getenv('DB_PASSWORD_FILE')
        if pw_path and os.path.exists(pw_path):
            try:
                with open(pw_path, 'r', encoding='utf-8') as f:
                    db_pw = f.read().strip()
            except Exception:
                db_pw = None
        if not db_pw:
            db_pw = os.getenv('DB_PASSWORD', '')
        db_url = f"postgresql://{db_user}:{db_pw}@{db_host}:5432/{db_name}"
        logger.info(f"Initializing AuthService with db_url: {db_url}")
        auth_service = AuthService(db_url)
        logger.info(f"AuthService initialized, db_available: {auth_service.db_available}")
    
    # Skip security checks for static files and health checks
    if request.endpoint in ['static', 'health_check', 'metrics']:
        return
    
    # Rate limiting check
    if not auth_service.check_rate_limit(request.remote_addr, 'request', limit=100, window=60):
        return jsonify({'error': 'Rate limit exceeded'}), 429
    
    # DLP Check for request data
    if request.method in ['POST', 'PUT', 'PATCH']:
        request_data = request.get_data(as_text=True)
        if request_data:
            dlp_result = dlp_check(request_data, f'request_{request.endpoint}')
            if dlp_result['violation']:
                # Log DLP violation but don't block the request
                auth_service.log_security_event(
                    event_type='dlp_violation',
                    severity='high',
                    source_ip=request.remote_addr,
                    details=f'DLP violation in {request.endpoint}: {dlp_result["findings"]}'
                )
    
    # Enhanced security monitoring
    threats = enhanced_security_monitoring()
    if threats:
        logger.warning(f"Security threats detected: {threats}")
    
    # Log request for audit (with data masking)
    if current_user.is_authenticated:
        # Mask sensitive data in user agent and other fields
        masked_user_agent = mask_sensitive_data(request.headers.get('User-Agent', ''))
        masked_ip = mask_sensitive_data(request.remote_addr)
        
        auth_service.log_audit_event(
            user_id=current_user.id,
            username=current_user.username,
            action='page_access',
            resource=request.endpoint,
            ip_address=masked_ip,
            user_agent=masked_user_agent,
            details=f'Accessed {request.endpoint}'
        )

# Correlation ID middleware and basic request logging
@app.before_request
def _before_request():
    g.correlation_id = request.headers.get('X-Correlation-Id', str(uuid.uuid4()))

@app.after_request
def _after_request(resp):
    try:
        resp.headers['X-Correlation-Id'] = g.correlation_id
    except Exception:
        pass
    return resp

@app.errorhandler(Exception)
def _handle_exc(e):
    logger.error('unhandled_exception', error=str(e), path=getattr(request, 'path', None),
                 method=getattr(request, 'method', None), cid=getattr(g, 'correlation_id', None))
    try:
        ERROR_COUNT.inc()
    except Exception:
        pass
    return jsonify({'error': 'Internal Server Error', 'correlation_id': getattr(g, 'correlation_id', None)}), 500

# Authentication routes
@app.route('/login', methods=['GET', 'POST'])
@limiter.limit("5 per minute")
def login():
    """Login page and authentication"""
    logger.info(f"Login route called - method: {request.method}")
    
    if request.method == 'POST':
        logger.info("Processing POST login request")
        username = request.form.get('username')
        password = request.form.get('password')
        
        logger.info(f"Login attempt for username: {username}")
        
        if not username or not password:
            logger.info("Missing username or password")
            return render_template('login.html', error='Please provide username and password')
        
        logger.info("Checking rate limiting")
        # Check rate limiting for login attempts
        if not auth_service.check_rate_limit(request.remote_addr, 'login_attempt', limit=5, window=300):
            logger.info("Rate limit exceeded")
            auth_service.log_security_event(
                event_type='rate_limit_exceeded',
                severity='high',
                source_ip=request.remote_addr,
                details='Login rate limit exceeded'
            )
            return render_template('login.html', error='Too many login attempts. Please try again later.')
        
        logger.info("Calling authenticate_user")
        try:
            user = auth_service.authenticate_user(username, password)
            logger.info(f"Authentication result: {user is not None}")
        except Exception as e:
            logger.error(f"Authentication error: {str(e)}")
            return render_template('login.html', error='Authentication service error')
        
        if user:
            logger.info(f"Login successful for user: {username}")
            login_user(user)
            session.permanent = True
            app.permanent_session_lifetime = timedelta(hours=8)
            
            # Log successful login
            auth_service.log_audit_event(
                user_id=user.id,
                username=user.username,
                action='login_success',
                ip_address=request.remote_addr,
                user_agent=request.headers.get('User-Agent'),
                details='User logged in successfully'
            )
            
            logger.info("Redirecting to dashboard")
            return redirect(url_for('dashboard'))
        else:
            logger.info(f"Login failed for user: {username}")
            return render_template('login.html', error='Invalid username or password')
    
    logger.info("Rendering login page")
    return render_template('login.html')

@app.route('/logout')
@login_required
def logout():
    """Logout user"""
    if current_user.is_authenticated:
        auth_service.log_audit_event(
            user_id=current_user.id,
            username=current_user.username,
            action='logout',
            ip_address=request.remote_addr,
            user_agent=request.headers.get('User-Agent'),
            details='User logged out'
        )
    
    logout_user()
    return redirect(url_for('login'))

@app.route('/profile')
@login_required
def profile():
    """User profile page"""
    return render_template('profile.html', user=current_user)

# Role-based access control decorator
def require_role(role):
    """Decorator to require specific role"""
    def decorator(f):
        @login_required
        def decorated_function(*args, **kwargs):
            if not current_user.is_authenticated:
                return redirect(url_for('login'))
            
            if current_user.role != role:
                flash('Access denied. Insufficient privileges.', 'error')
                return redirect(url_for('dashboard'))
            
            return f(*args, **kwargs)
        
        # Make the function name unique to avoid Flask endpoint conflicts
        decorated_function.__name__ = f.__name__
        return decorated_function
    return decorator

class DataQualityReporter:
    """Data Quality Reporter for generating reports and metrics"""
    
    def __init__(self):
        """Initialize the reporter with database connection"""
        # Read DB password from file if provided
        db_pass_file = os.getenv('DB_PASSWORD_FILE')
        db_password = None
        if db_pass_file and os.path.exists(db_pass_file):
            try:
                with open(db_pass_file, 'r', encoding='utf-8') as f:
                    db_password = f.read().strip()
            except Exception:
                db_password = None
        db_password = db_password or os.getenv('DB_PASSWORD', 'your_db_password')
        self.db_url = f"postgresql://{os.getenv('DB_USER', 'sap_user')}:{db_password}@{os.getenv('DB_HOST', 'postgres')}:5432/{os.getenv('DB_NAME', 'sap_data_quality')}"
        self.engine = create_engine(self.db_url)
        
        # Ollama configuration
        self.ollama_url = os.getenv('OLLAMA_URL', 'http://host.docker.internal:11434')
        self.ollama_model = os.getenv('OLLAMA_MODEL', 'phi3')
    
    @with_cache(ttl=300, key_prefix='validation_summary')
    def get_validation_summary(self, days: int = 30) -> Dict[str, Any]:
        """Get validation summary for the last N days"""
        try:
            since_date = datetime.utcnow() - timedelta(days=days)
            
            query = text("""
                SELECT 
                    validation_type as dataset_name,
                    validation_name as rule_name,
                    CASE WHEN success_rate >= 0.95 THEN 'passed' ELSE 'failed' END as status,
                    error_details as results,
                    COUNT(*) as count
                FROM validation_results 
                WHERE created_at >= :since_date
                GROUP BY validation_type, validation_name, status, error_details
                ORDER BY validation_type, validation_name
            """)
            
            with self.engine.connect() as conn:
                result = conn.execute(query, {'since_date': since_date})
                rows = result.fetchall()
            
            summary = {}
            for row in rows:
                dataset = row.dataset_name
                if dataset not in summary:
                    summary[dataset] = {
                        'total_validations': 0,
                        'passed_validations': 0,
                        'failed_validations': 0,
                        'success_rate': 0.0,
                        'rules': {}
                    }
                
                # Parse the JSON results
                results = json.loads(row.results) if isinstance(row.results, str) else row.results
                success_rate = results.get('success_rate', 0.0)
                passed_records = results.get('passed_records', 0)
                failed_records = results.get('failed_records', 0)
                total_records = results.get('total_records', 0)
                
                summary[dataset]['total_validations'] += row.count
                if row.status == 'passed':
                    summary[dataset]['passed_validations'] += row.count
                else:
                    summary[dataset]['failed_validations'] += row.count
                
                # Convert Decimal to float for JSON serialization
                success_rate = float(success_rate) if hasattr(success_rate, '__float__') else success_rate
                
                if row.rule_name not in summary[dataset]['rules']:
                    summary[dataset]['rules'][row.rule_name] = {
                        'total': 0,
                        'passed': 0,
                        'failed': 0,
                        'success_rate': 0.0,
                        'avg_success_rate': 0.0
                    }
                
                summary[dataset]['rules'][row.rule_name]['total'] += row.count
                if row.status == 'passed':
                    summary[dataset]['rules'][row.rule_name]['passed'] += row.count
                else:
                    summary[dataset]['rules'][row.rule_name]['failed'] += row.count
                summary[dataset]['rules'][row.rule_name]['avg_success_rate'] = success_rate
            
            # Calculate success rates using actual database values
            for dataset in summary.values():
                if dataset['total_validations'] > 0:
                    # Calculate overall success rate
                    dataset['success_rate'] = (dataset['passed_validations'] / dataset['total_validations']) * 100
                
                for rule in dataset['rules'].values():
                    if rule['total'] > 0:
                        # Calculate rule success rate
                        rule['success_rate'] = (rule['passed'] / rule['total']) * 100
            
            return summary
            
        except Exception as e:
            logger.error(f"Failed to get validation summary: {str(e)}")
            return {}
    
    @with_cache(ttl=300, key_prefix='recent_issues')
    def get_recent_issues(self, limit: int = 50) -> List[Dict[str, Any]]:
        """Get recent validation issues"""
        try:
            query = text("""
                SELECT 
                    id,
                    validation_type as dataset_name,
                    validation_name as rule_name,
                    CASE WHEN success_rate >= 0.95 THEN 'passed' ELSE 'failed' END as status,
                    error_details as results,
                    created_at
                FROM validation_results 
                ORDER BY created_at DESC
                LIMIT :limit
            """)
            
            with self.engine.connect() as conn:
                result = conn.execute(query, {'limit': limit})
                rows = result.fetchall()
            
            print(f"DEBUG: Database query returned {len(rows)} rows", file=sys.stderr)
            print(f"DEBUG: Row IDs: {[row.id for row in rows]}", file=sys.stderr)
            print(f"DEBUG: Row statuses: {[row.status for row in rows]}", file=sys.stderr)
            print(f"DEBUG: Row dataset_names: {[row.dataset_name for row in rows]}", file=sys.stderr)
            issues = []
            for row in rows:
                print(f"DEBUG: Processing row {row.id}: {row.dataset_name} - {row.status}", file=sys.stderr)
                try:
                    # Parse the JSON results
                    results = json.loads(row.results) if isinstance(row.results, str) else row.results
                    issues_list = [results.get('error_details', 'No details available')] if results else []
                    metrics = {
                        'success_rate': results.get('success_rate', 0.0),
                        'total_records': results.get('total_records', 0),
                        'passed_records': results.get('passed_records', 0),
                        'failed_records': results.get('failed_records', 0)
                    }
                    
                    issue_data = {
                        'id': row.id,
                        'dataset_name': row.dataset_name,
                        'rule_name': row.rule_name,
                        'status': row.status,
                        'issues': issues_list,
                        'metrics': metrics,
                        'created_at': row.created_at.isoformat()
                    }
                    
                    issues.append(issue_data)
                    print(f"DEBUG: Added row {row.id} to issues list", file=sys.stderr)
                except Exception as e:
                    print(f"DEBUG: Exception processing row {row.id}: {str(e)}", file=sys.stderr)
                    logger.error(f"Failed to parse results for row {row.id}: {str(e)}")
            
            print(f"DEBUG: Final issues list length: {len(issues)}", file=sys.stderr)
            print(f"DEBUG: Final issues IDs: {[issue['id'] for issue in issues]}", file=sys.stderr)
            
            return issues
            
        except Exception as e:
            logger.error(f"Failed to get recent issues: {str(e)}")
            return []
    
    @with_cache(ttl=600, key_prefix='quality_trends')
    def get_quality_trends(self, days: int = 30) -> Dict[str, Any]:
        """Get data quality trends over time"""
        try:
            since_date = datetime.utcnow() - timedelta(days=days)
            # Compute daily averages from DB success_rate to smooth the chart
            query = text("""
                SELECT 
                    DATE(created_at) as date,
                    validation_type as dataset_name,
                    AVG(success_rate) * 100.0 as avg_success_pct,
                    COUNT(*) as validations
                FROM validation_results 
                WHERE created_at >= :since_date
                GROUP BY DATE(created_at), validation_type
                ORDER BY date, validation_type
            """)

            with self.engine.connect() as conn:
                result = conn.execute(query, {'since_date': since_date})
                rows = result.fetchall()

            trends: Dict[str, Any] = {}
            for row in rows:
                date_str = row.date.isoformat()
                dataset = row.dataset_name

                if dataset not in trends:
                    trends[dataset] = {}

                avg_success = float(row.avg_success_pct) if row.avg_success_pct is not None else 0.0
                avg_failed = max(0.0, 100.0 - avg_success)

                trends[dataset][date_str] = {
                    'avg_success_rate': avg_success,
                    'avg_failed_rate': avg_failed,
                    'total': int(row.validations)
                }

            return trends
            
        except Exception as e:
            logger.error(f"Failed to get quality trends: {str(e)}")
            return {}

    def get_all_data_context(self) -> Dict[str, Any]:
        """Get all data context for AI assistant"""
        try:
            context = {
                'validation_summary': self.get_validation_summary(),
                'recent_issues': self.get_recent_issues(limit=50),
                'quality_trends': self.get_quality_trends()
            }
            return context
        except Exception as e:
            logger.error(f"Failed to get data context: {str(e)}")
            return {}

    def chat_with_ollama(self, user_message: str, context_data: Dict[str, Any]) -> str:
        """Send message to Ollama and get response"""
        try:
            # Simplify the context to avoid timeout
            summary = context_data.get('validation_summary', {})
            recent_issues = context_data.get('recent_issues', [])
            
            # Create a simplified context
            context_str = f"""
            Data Quality Summary:
            - Total datasets: {len(summary)}
            - Recent issues count: {len(recent_issues)}
            - Sample datasets: {list(summary.keys())[:3] if summary else 'None'}
            """
            
            # Create system prompt
            system_prompt = """You are a Data Quality AI Assistant. You help users understand their data quality metrics, identify issues, and provide insights. Be concise and helpful."""
            
            # Prepare the request to Ollama
            ollama_request = {
                "model": self.ollama_model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"Context: {context_str}\n\nUser Question: {user_message}"}
                ],
                "stream": False
            }
            
            # Send request to Ollama with shorter timeout
            response = requests.post(
                f"{self.ollama_url}/api/chat",
                json=ollama_request,
                timeout=15
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('message', {}).get('content', 'Sorry, I could not process your request.')
            else:
                logger.error(f"Ollama API error: {response.status_code} - {response.text}")
                return "Sorry, I'm having trouble connecting to the AI service. Please try again later."
                
        except Exception as e:
            logger.error(f"Chat with Ollama failed: {str(e)}")
            return "Sorry, I encountered an error while processing your request. Please try again."
    
    def generate_quality_report(self, dataset_name: str = None, days: int = 30) -> Dict[str, Any]:
        """Generate comprehensive quality report"""
        try:
            summary = self.get_validation_summary(days)
            issues = self.get_recent_issues(100)
            trends = self.get_quality_trends(days)
            
            # Filter by dataset if specified
            if dataset_name:
                summary = {dataset_name: summary.get(dataset_name, {})}
                issues = [issue for issue in issues if issue['dataset_name'] == dataset_name]
                trends = {dataset_name: trends.get(dataset_name, {})}
            
            # Calculate overall metrics
            total_validations = sum(dataset['total_validations'] for dataset in summary.values())
            total_passed = sum(dataset['passed_validations'] for dataset in summary.values())
            overall_success_rate = (total_passed / total_validations * 100) if total_validations > 0 else 0
            
            report = {
                'generated_at': datetime.utcnow().isoformat(),
                'period_days': days,
                'overall_metrics': {
                    'total_validations': total_validations,
                    'total_passed': total_passed,
                    'total_failed': total_validations - total_passed,
                    'overall_success_rate': overall_success_rate
                },
                'dataset_summary': summary,
                'recent_issues': issues,
                'quality_trends': trends
            }
            
            return report
            
        except Exception as e:
            logger.error(f"Failed to generate quality report: {str(e)}")
            return {
                'error': str(e),
                'generated_at': datetime.utcnow().isoformat()
            }
    
    def get_all_data_context(self) -> Dict[str, Any]:
        """Get comprehensive data quality context for the chatbot"""
        try:
            # Get all data sections
            validation_summary = self.get_validation_summary(30)
            recent_issues = self.get_recent_issues(50)
            quality_trends = self.get_quality_trends(30)
            
            # Calculate overall metrics
            total_validations = sum(dataset.get('total_validations', 0) for dataset in validation_summary.values())
            total_passed = sum(dataset.get('passed_validations', 0) for dataset in validation_summary.values())
            total_failed = sum(dataset.get('failed_validations', 0) for dataset in validation_summary.values())
            overall_success_rate = (total_passed / total_validations * 100) if total_validations > 0 else 0
            
            # Get dataset-specific metrics
            dataset_metrics = {}
            for dataset_name, dataset_data in validation_summary.items():
                dataset_metrics[dataset_name] = {
                    'total_validations': dataset_data.get('total_validations', 0),
                    'passed_validations': dataset_data.get('passed_validations', 0),
                    'failed_validations': dataset_data.get('failed_validations', 0),
                    'success_rate': dataset_data.get('success_rate', 0),
                    'rules': dataset_data.get('rules', {})
                }
            
            # Get recent issues summary
            recent_issues_summary = {
                'total_issues': len(recent_issues),
                'failed_count': len([issue for issue in recent_issues if issue.get('status') == 'failed']),
                'passed_count': len([issue for issue in recent_issues if issue.get('status') == 'passed']),
                'by_dataset': {},
                'by_rule': {}
            }
            
            for issue in recent_issues:
                dataset = issue.get('dataset_name', 'unknown')
                rule = issue.get('rule_name', 'unknown')
                
                if dataset not in recent_issues_summary['by_dataset']:
                    recent_issues_summary['by_dataset'][dataset] = {'failed': 0, 'passed': 0}
                if rule not in recent_issues_summary['by_rule']:
                    recent_issues_summary['by_rule'][rule] = {'failed': 0, 'passed': 0}
                
                if issue.get('status') == 'failed':
                    recent_issues_summary['by_dataset'][dataset]['failed'] += 1
                    recent_issues_summary['by_rule'][rule]['failed'] += 1
                else:
                    recent_issues_summary['by_dataset'][dataset]['passed'] += 1
                    recent_issues_summary['by_rule'][rule]['passed'] += 1
            
            # Get quality trends summary
            trends_summary = {}
            for dataset_name, trend_data in quality_trends.items():
                if trend_data and 'dates' in trend_data and 'success_rates' in trend_data:
                    dates = trend_data['dates']
                    rates = trend_data['success_rates']
                    if dates and rates:
                        trends_summary[dataset_name] = {
                            'latest_rate': rates[-1] if rates else 0,
                            'average_rate': sum(rates) / len(rates) if rates else 0,
                            'trend_direction': 'improving' if len(rates) > 1 and rates[-1] > rates[0] else 'declining' if len(rates) > 1 and rates[-1] < rates[0] else 'stable',
                            'data_points': len(rates)
                        }
            
            context = {
                'overall_metrics': {
                    'total_validations': total_validations,
                    'total_passed': total_passed,
                    'total_failed': total_failed,
                    'overall_success_rate': overall_success_rate
                },
                'dataset_metrics': dataset_metrics,
                'recent_issues': recent_issues,
                'recent_issues_summary': recent_issues_summary,
                'quality_trends': quality_trends,
                'trends_summary': trends_summary,
                'current_time': datetime.utcnow().isoformat()
            }
            return context
        except Exception as e:
            logger.error(f"Failed to get data context: {str(e)}")
            return {}
    
    def chat_with_ollama(self, user_message: str) -> Dict[str, Any]:
        """Send message to Ollama and get response with data context"""
        try:
            # Get all data quality context
            data_context = self.get_all_data_context()
            
            # Debug: Print the data context
            logger.info(f"Data context keys: {list(data_context.keys())}")
            logger.info(f"Validation summary keys: {list(data_context.get('validation_summary', {}).keys())}")
            
            # Create optimized context for faster response
            overall_metrics = data_context.get('overall_metrics', {})
            dataset_metrics = data_context.get('dataset_metrics', {})
            recent_issues_summary = data_context.get('recent_issues_summary', {})
            
            # Build concise context string
            context_parts = []
            
            # Overall metrics
            total_validations = overall_metrics.get('total_validations', 0)
            total_passed = overall_metrics.get('total_passed', 0)
            total_failed = overall_metrics.get('total_failed', 0)
            overall_success_rate = overall_metrics.get('overall_success_rate', 0)
            context_parts.append(f"Overall: {total_validations} validations, {overall_success_rate:.1f}% success rate")
            
            # Dataset metrics (top 3)
            dataset_info = []
            for i, (dataset_name, metrics) in enumerate(dataset_metrics.items()):
                if i >= 3:  # Limit to top 3 datasets
                    break
                success_rate = metrics.get('success_rate', 0)
                dataset_info.append(f"{dataset_name}: {success_rate:.1f}%")
            if dataset_info:
                context_parts.append(f"Datasets: {'; '.join(dataset_info)}")
            
            # Recent issues summary
            total_issues = recent_issues_summary.get('total_issues', 0)
            failed_count = recent_issues_summary.get('failed_count', 0)
            context_parts.append(f"Recent: {total_issues} issues, {failed_count} failed")
            
            context_str = " | ".join(context_parts)
            
            system_prompt = """You are a Data Quality AI Assistant. Answer questions about data quality metrics, datasets, and validation issues. Be specific and helpful."""
            
            # Create optimized user message
            enhanced_message = f"""Context: {context_str}

Question: {user_message}

Answer based on the data quality metrics above."""
            
            ollama_request = {
                "model": self.ollama_model,
                "messages": [
                    {"role": "system", "content": "You are a Data Quality Assistant. Answer questions about data quality using the provided metrics."},
                    {"role": "user", "content": enhanced_message}
                ],
                "stream": False
            }
            
            # Send request to Ollama
            response = requests.post(
                f"{self.ollama_url}/api/chat",
                json=ollama_request,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return {
                    'status': 'success',
                    'response': result.get('message', {}).get('content', 'No response received'),
                    'model': self.ollama_model,
                    'timestamp': datetime.utcnow().isoformat()
                }
            else:
                logger.error(f"Ollama request failed: {response.status_code} - {response.text}")
                return {
                    'status': 'error',
                    'message': f'Ollama service error: {response.status_code}',
                    'timestamp': datetime.utcnow().isoformat()
                }
                
        except requests.exceptions.RequestException as e:
            logger.error(f"Ollama connection error: {str(e)}")
            return {
                'status': 'error',
                'message': f'Ollama service unavailable: {str(e)}',
                'timestamp': datetime.utcnow().isoformat()
            }
        except Exception as e:
            logger.error(f"Chat error: {str(e)}")
            return {
                'status': 'error',
                'message': f'Internal error: {str(e)}',
                'timestamp': datetime.utcnow().isoformat()
            }

# Initialize reporter
reporter = DataQualityReporter()

# Database configuration for vector service
# Prefer AI-specific env/secrets first, then fall back
_db_pw = None
for var in ("AI_DB_PASSWORD_FILE", "DB_PASSWORD_FILE"):
    p = os.getenv(var)
    if p and os.path.exists(p):
        try:
            with open(p, 'r', encoding='utf-8') as f:
                _db_pw = f.read().strip()
                break
        except Exception:
            pass
if not _db_pw:
    _db_pw = os.getenv('AI_DB_PASSWORD', os.getenv('DB_PASSWORD', 'your_db_password'))

db_config = {
    'host': os.getenv('AI_DB_HOST', os.getenv('DB_HOST', 'postgres')),
    'database': os.getenv('AI_DB_NAME', os.getenv('DB_NAME', 'sap_data_quality')),
    'user': os.getenv('AI_DB_USER', os.getenv('DB_USER', 'sap_user')),
    'password': _db_pw,
    'port': 5432
}

# Initialize vector service
vector_service = VectorService(db_config)

"""AI Agents feature flag
# AI agents can be disabled via environment variable to harden production by default.
# Set AI_AGENTS_ENABLED=true to enable.
"""
ai_agent_manager = None

def init_ai_agents():
    """Initialize AI agents if enabled by configuration"""
    global ai_agent_manager
    try:
        enabled = str(os.getenv('AI_AGENTS_ENABLED', 'false')).lower() in ('1', 'true', 'yes')
        if not enabled:
            app.agent_manager = None
            logger.info("AI agents disabled by configuration")
            return

        config = AgentConfig(
            validation_rule_enabled=True,
            ab_testing_enabled=True,
            missing_data_enabled=True,
            script_generation_enabled=True,
            schedule_interval_minutes=30,
            max_concurrent_agents=4
        )
        ai_agent_manager = AIAgentManager(config)
        app.agent_manager = ai_agent_manager
        logger.info("AI agents initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize AI agents: {e}")

# Initialize AI agents when app starts
init_ai_agents()

# API Resources
class ValidationSummaryResource(Resource):
    """API endpoint for validation summary"""
    
    @login_required
    @limiter.limit("100 per hour")
    def get(self):
        """Get validation summary"""
        REQUEST_COUNT.labels(endpoint='validation_summary').inc()
        
        try:
            days = request.args.get('days', 30, type=int)
            summary = reporter.get_validation_summary(days)
            
            return {
                'status': 'success',
                'data': summary,
                'timestamp': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Validation summary failed: {str(e)}")
            return {
                'status': 'error',
                'message': str(e)
            }, 500

# Risk Register API
@app.route('/api/risks', methods=['GET', 'POST'])
@login_required
@limiter.limit("100 per hour")
def risks_collection():
    try:
        if request.method == 'POST':
            data = request.get_json() or {}
            insert_sql = text(
                """
                INSERT INTO risk_register
                (title, category, likelihood, impact, status, owner, due_date, priority, description, causes, consequences, mitigation)
                VALUES (:title, :category, :likelihood, :impact, :status, :owner, :due_date, :priority, :description, :causes, :consequences, :mitigation)
                RETURNING id
                """
            )
            params = {
                'title': data.get('title'),
                'category': data.get('category'),
                'likelihood': data.get('likelihood'),
                'impact': data.get('impact'),
                'status': data.get('status'),
                'owner': data.get('owner'),
                'due_date': data.get('dueDate'),
                'priority': data.get('priority'),
                'description': data.get('description'),
                'causes': data.get('causes'),
                'consequences': data.get('consequences'),
                'mitigation': data.get('mitigation'),
            }
            with reporter.engine.begin() as conn:
                new_id = conn.execute(insert_sql, params).scalar()
            return jsonify({'id': new_id}), 201

        # GET with optional filters
        severity = request.args.get('severity')
        status = request.args.get('status')
        category = request.args.get('category')
        search = request.args.get('search')

        base_sql = "SELECT * FROM risk_register"
        conditions = []
        bind = {}
        if status:
            conditions.append("status = :status")
            bind['status'] = status
        if category:
            conditions.append("category = :category")
            bind['category'] = category
        if search:
            conditions.append("(title ILIKE :q OR description ILIKE :q OR mitigation ILIKE :q)")
            bind['q'] = f"%{search}%"
        if severity in ('high', 'medium', 'low'):
            # Compute severity from likelihood*impact: 9 high, 6-8 medium, 1-5 low
            sev_clause = {
                'high': "(likelihood * impact) >= 9",
                'medium': "(likelihood * impact) BETWEEN 6 AND 8",
                'low': "(likelihood * impact) <= 5",
            }[severity]
            conditions.append(sev_clause)
        if conditions:
            base_sql += " WHERE " + " AND ".join(conditions)
        base_sql += " ORDER BY created_at DESC"

        with reporter.engine.connect() as conn:
            rows = conn.execute(text(base_sql), bind).mappings().all()

        def to_frontend(row):
            score = (row['likelihood'] or 0) * (row['impact'] or 0)
            # derive severity text for convenience if needed by UI
            return {
                'id': row['id'],
                'title': row['title'],
                'description': row['description'],
                'category': row['category'],
                'likelihood': row['likelihood'],
                'impact': row['impact'],
                'riskScore': score,
                'status': row['status'],
                'owner': row['owner'],
                'dueDate': row['due_date'].isoformat() if row['due_date'] else None,
                'priority': row['priority'],
                'causes': row['causes'],
                'consequences': row['consequences'],
                'mitigation': row['mitigation'],
                'createdAt': row['created_at'].isoformat() if row['created_at'] else None,
                'updatedAt': row['updated_at'].isoformat() if row['updated_at'] else None,
            }

        return jsonify([to_frontend(r) for r in rows])
    
    except Exception as e:
        logger.error(f"Risks API error: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/risks/<int:risk_id>', methods=['GET', 'PUT', 'DELETE'])
@login_required
@limiter.limit("100 per hour")
def risks_resource(risk_id: int):
    try:
        if request.method == 'GET':
            with reporter.engine.connect() as conn:
                row = conn.execute(text("SELECT * FROM risk_register WHERE id = :id"), {'id': risk_id}).mappings().first()
            if not row:
                return jsonify({'error': 'Not found'}), 404
            score = (row['likelihood'] or 0) * (row['impact'] or 0)
            return jsonify({
                'id': row['id'],
                'title': row['title'],
                'description': row['description'],
                'category': row['category'],
                'likelihood': row['likelihood'],
                'impact': row['impact'],
                'riskScore': score,
                'status': row['status'],
                'owner': row['owner'],
                'dueDate': row['due_date'].isoformat() if row['due_date'] else None,
                'priority': row['priority'],
                'causes': row['causes'],
                'consequences': row['consequences'],
                'mitigation': row['mitigation'],
                'createdAt': row['created_at'].isoformat() if row['created_at'] else None,
                'updatedAt': row['updated_at'].isoformat() if row['updated_at'] else None,
            })

        if request.method == 'PUT':
            data = request.get_json() or {}
            update_sql = text(
                """
                UPDATE risk_register
                SET title = :title,
                    category = :category,
                    likelihood = :likelihood,
                    impact = :impact,
                    status = :status,
                    owner = :owner,
                    due_date = :due_date,
                    priority = :priority,
                    description = :description,
                    causes = :causes,
                    consequences = :consequences,
                    mitigation = :mitigation,
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = :id
                """
            )
            params = {
                'id': risk_id,
                'title': data.get('title'),
                'category': data.get('category'),
                'likelihood': data.get('likelihood'),
                'impact': data.get('impact'),
                'status': data.get('status'),
                'owner': data.get('owner'),
                'due_date': data.get('dueDate'),
                'priority': data.get('priority'),
                'description': data.get('description'),
                'causes': data.get('causes'),
                'consequences': data.get('consequences'),
                'mitigation': data.get('mitigation'),
            }
            with reporter.engine.begin() as conn:
                conn.execute(update_sql, params)
            return jsonify({'id': risk_id})

        # DELETE
        with reporter.engine.begin() as conn:
            conn.execute(text("DELETE FROM risk_register WHERE id = :id"), {'id': risk_id})
        return jsonify({'deleted': True})

    except Exception as e:
        logger.error(f"Risks API error: {e}")
        return jsonify({'error': str(e)}), 500

class RecentIssuesResource(Resource):
    """API endpoint for recent issues"""
    
    @login_required
    @limiter.limit("100 per hour")
    def get(self):
        """Get recent validation issues"""
        REQUEST_COUNT.labels(endpoint='recent_issues').inc()
        
        try:
            limit = request.args.get('limit', 50, type=int)
            logger.info(f"Getting recent issues with limit: {limit}")
            issues = reporter.get_recent_issues(limit)
            logger.info(f"Retrieved {len(issues)} issues")
            
            return {
                'status': 'success',
                'data': issues,
                'timestamp': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Recent issues failed: {str(e)}")
            return {
                'status': 'error',
                'message': str(e)
            }, 500

class QualityReportResource(Resource):
    """API endpoint for quality reports"""
    
    @login_required
    @limiter.limit("50 per hour")
    def get(self):
        """Generate quality report"""
        REQUEST_COUNT.labels(endpoint='quality_report').inc()
        
        try:
            dataset_name = request.args.get('dataset')
            days = request.args.get('days', 30, type=int)
            
            report = reporter.generate_quality_report(dataset_name, days)
            REPORT_GENERATION_COUNT.labels(report_type='quality_report').inc()
            
            return {
                'status': 'success',
                'data': report,
                'timestamp': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Quality report failed: {str(e)}")
            return {
                'status': 'error',
                'message': str(e)
            }, 500

# Register API resources
api.add_resource(ValidationSummaryResource, '/api/validation-summary')
api.add_resource(RecentIssuesResource, '/api/recent-issues')
api.add_resource(QualityReportResource, '/api/quality-report')

# Validation workflow endpoints
@app.route('/api/validations/run', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def run_validations():
    """Trigger validations by extracting from mock-sap and calling validation-engine."""
    try:
        # Extract from mock-sap (port 8000)
        equip = requests.get('http://mock-sap:8000/extract/equipment', timeout=15).json().get('data', [])
        fl = requests.get('http://mock-sap:8000/extract/functional-locations', timeout=15).json().get('data', [])
        mo = requests.get('http://mock-sap:8000/extract/maintenance-orders', timeout=15).json().get('data', [])

        # Validate via validation-engine (port 8001)
        eq_res = requests.post('http://validation-engine:8001/validate/equipment', json={'data': equip}, timeout=30).json()
        mo_res = requests.post('http://validation-engine:8001/validate/maintenance-orders', json={'data': mo}, timeout=30).json()
        cr_res = requests.post('http://validation-engine:8001/validate/cross-reference', json={'equipment': equip, 'functional_locations': fl, 'maintenance_orders': mo}, timeout=30).json()

        return jsonify({'success': True, 'results': {'equipment': eq_res, 'maintenance_orders': mo_res, 'cross_reference': cr_res}, 'timestamp': datetime.utcnow().isoformat()})
    except Exception as e:
        logger.error(f"Run validations failed: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

# Rules API (reads from SQLite rules.db created by AI agents)
@app.route('/api/rules', methods=['GET', 'POST'])
@login_required
@limiter.limit("60 per hour")
def list_rules():
    import sqlite3
    if request.method == 'POST':
        try:
            payload = request.get_json() or {}
            required = ['name', 'sql_condition']
            missing = [k for k in required if not payload.get(k)]
            if missing:
                return jsonify({'error': f"missing fields: {', '.join(missing)}"}), 400
            db_path = "/app/data/rules.db"
            conn = sqlite3.connect(db_path)
            cur = conn.cursor()
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS validation_rules (
                    id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    description TEXT,
                    sql_condition TEXT NOT NULL,
                    severity TEXT,
                    category TEXT,
                    created_by TEXT,
                    created_at TEXT,
                    is_active BOOLEAN,
                    performance_metrics TEXT
                )
                """
            )
            import uuid, datetime, json as pyjson
            rule_id = payload.get('id') or str(uuid.uuid4())
            now = datetime.datetime.utcnow().isoformat()
            cur.execute(
                """
                INSERT OR REPLACE INTO validation_rules
                (id, name, description, sql_condition, severity, category, created_by, created_at, is_active, performance_metrics)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    rule_id,
                    payload.get('name'),
                    payload.get('description'),
                    payload.get('sql_condition'),
                    payload.get('severity'),
                    payload.get('category'),
                    payload.get('created_by') or current_user.username,
                    now,
                    1 if payload.get('is_active', True) else 0,
                    pyjson.dumps(payload.get('performance_metrics') or {})
                )
            )
            conn.commit()
            conn.close()
            logger.info(f"Rule created: {rule_id}")
            return jsonify({'id': rule_id}), 201
        except Exception as e:
            try:
                conn.close()
            except Exception:
                pass
            logger.error(f"Create rule failed: {e}")
            return jsonify({'error': str(e)}), 500
    rules = []
    try:
        db_path = "/app/data/rules.db"
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        cur.execute("SELECT id, name, description, sql_condition, severity, category, created_by, created_at, is_active, performance_metrics FROM validation_rules ORDER BY created_at DESC")
        for row in cur.fetchall():
            rules.append({
                'id': row['id'],
                'name': row['name'],
                'description': row['description'],
                'sql_condition': row['sql_condition'],
                'severity': row['severity'],
                'category': row['category'],
                'created_by': row['created_by'],
                'created_at': row['created_at'],
                'is_active': bool(row['is_active']),
                'performance_metrics': row['performance_metrics']
            })
        conn.close()
        return jsonify(rules)
    except Exception as e:
        try:
            conn.close()
        except Exception:
            pass
        return jsonify({'error': str(e)}), 500

# Optional: promote a rule into Postgres (store metadata in configuration as example)
@app.route('/api/rules/<rule_id>/promote', methods=['POST'])
@login_required
@require_role('admin')
@limiter.limit("20 per hour")
def promote_rule(rule_id):
    import sqlite3
    try:
        # Fetch from SQLite
        conn = sqlite3.connect('/app/data/rules.db')
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        cur.execute("SELECT id, name, sql_condition, severity, category FROM validation_rules WHERE id = ?", (rule_id,))
        row = cur.fetchone()
        conn.close()
        if not row:
            return jsonify({'error': 'Rule not found'}), 404
        # Store promotion marker in Postgres configuration (placeholder for now)
        with reporter.engine.begin() as pg:
            pg.execute(text("""
                INSERT INTO configuration (config_key, config_value, config_type, description)
                VALUES (:k, :v, 'string', 'Promoted validation rule')
                ON CONFLICT (config_key) DO UPDATE SET config_value = EXCLUDED.config_value, updated_at = CURRENT_TIMESTAMP
            """), {
                'k': f"promoted_rule_{row['id']}",
                'v': f"{row['name']}|{row['sql_condition']}|{row['severity']}|{row['category']}"
            })
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# Vector service endpoints
@app.route('/api/vector/search', methods=['POST'])
@login_required
@limiter.limit("50 per hour")
def semantic_search():
    """Perform semantic search"""
    try:
        data = request.get_json()
        query = data.get('query', '')
        data_types = data.get('data_types', None)
        similarity_threshold = data.get('similarity_threshold', 0.7)
        limit = data.get('limit', 10)
        
        if not query:
            return jsonify({'error': 'Query is required'}), 400
        
        results = vector_service.semantic_search(query, data_types, similarity_threshold, limit)
        
        return jsonify({
            'status': 'success',
            'data': results,
            'query': query,
            'count': len(results)
        })
        
    except Exception as e:
        logger.error(f"Semantic search failed: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/vector/embeddings/populate', methods=['POST'])
@login_required
@require_role('admin')
@limiter.limit("10 per hour")
def populate_embeddings():
    """Populate embeddings from existing data"""
    try:
        counts = vector_service.populate_embeddings_from_data()
        
        return jsonify({
            'status': 'success',
            'message': 'Embeddings populated successfully',
            'counts': counts
        })
        
    except Exception as e:
        logger.error(f"Failed to populate embeddings: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/vector/embeddings/stats')
@login_required
@limiter.limit("30 per hour")
def get_embedding_stats():
    """Get embedding statistics"""
    try:
        stats = vector_service.get_embedding_stats()
        
        return jsonify({
            'status': 'success',
            'data': stats
        })
        
    except Exception as e:
        logger.error(f"Failed to get embedding stats: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/vector/status')
@login_required
@limiter.limit("30 per hour")
def get_vector_status():
    """Get vector service status and capabilities"""
    try:
        stats = vector_service.get_embedding_stats()
        model_status = vector_service.vectorizer is not None
        
        return jsonify({
            'status': 'success',
            'data': {
                'model_loaded': model_status,
                'embeddings_count': sum(stats.get(data_type, {}).get('count', 0) for data_type in stats),
                'data_types': list(stats.keys()),
                'capabilities': {
                    'semantic_search': True,
                    'embedding_generation': model_status,
                    'context_enhancement': True
                }
            }
        })
        
    except Exception as e:
        logger.error(f"Failed to get vector status: {str(e)}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/ai/context', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def get_ai_context():
    """Get comprehensive AI context for a query"""
    try:
        data = request.get_json()
        query = data.get('query', '')
        
        if not query:
            return jsonify({'error': 'Query is required'}), 400
        
        # Initialize comprehensive data context provider
        context_provider = ComprehensiveDataContextProvider()
        
        # Get comprehensive context
        comprehensive_context = context_provider.get_comprehensive_context(query)
        
        return jsonify({
            'status': 'success',
            'query': query,
            'comprehensive_context': comprehensive_context,
            'summary': {
                'data_sources_count': len(comprehensive_context.get('data_sources', {})),
                'calculations_available': len(comprehensive_context.get('calculations', {})),
                'report_types': len(comprehensive_context.get('report_mechanisms', {}).get('report_types', {})),
                'system_health': comprehensive_context.get('system_status', {}).get('overall_status', 'unknown')
            }
        })
        
    except Exception as e:
        logger.error(f"Failed to get AI context: {e}")
        return jsonify({'error': str(e)}), 500

# Security API endpoints
@app.route('/api/security/events')
@login_required
@require_role('admin')
@limiter.limit("50 per hour")
def security_events():
    """Get security events and metrics"""
    try:
        # Get security events from the last 24 hours
        query = text("""
            SELECT 
                event_type,
                severity,
                source_ip,
                username,
                details,
                timestamp,
                resolved
            FROM security_events 
            WHERE timestamp >= CURRENT_TIMESTAMP - INTERVAL '24 hours'
            ORDER BY timestamp DESC
            LIMIT 100
        """)
        
        with reporter.engine.connect() as conn:
            result = conn.execute(query)
            events = []
            for row in result:
                events.append({
                    'event_type': row.event_type,
                    'severity': row.severity,
                    'source_ip': row.source_ip,
                    'username': row.username,
                    'details': row.details,
                    'timestamp': row.timestamp.isoformat(),
                    'resolved': row.resolved
                })
        
        # Get metrics
        metrics_query = text("""
            SELECT 
                severity,
                COUNT(*) as count
            FROM security_events 
            WHERE timestamp >= CURRENT_TIMESTAMP - INTERVAL '24 hours'
            GROUP BY severity
        """)
        
        with reporter.engine.connect() as conn:
            result = conn.execute(metrics_query)
            metrics = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0}
            for row in result:
                metrics[row.severity] = row.count
        
        # Get additional metrics
        additional_metrics = {
            'active_users': len([u for u in auth_service.get_all_users() if u.is_active]),
            'failed_logins': len([e for e in events if e['event_type'] == 'login_failed'])
        }
        metrics.update(additional_metrics)
        
        # Get chart data
        chart_query = text("""
            SELECT 
                event_type,
                COUNT(*) as count
            FROM security_events 
            WHERE timestamp >= CURRENT_TIMESTAMP - INTERVAL '24 hours'
            GROUP BY event_type
        """)
        
        with reporter.engine.connect() as conn:
            result = conn.execute(chart_query)
            chart_data = {'login_failed': 0, 'rate_limit': 0, 'unauthorized': 0, 'suspicious': 0}
            for row in result:
                if row.event_type in chart_data:
                    chart_data[row.event_type] = row.count
        
        return jsonify({
            'status': 'success',
            'data': {
                'events': events,
                'metrics': metrics,
                'chart_data': chart_data
            }
        })
        
    except Exception as e:
        logger.error(f"Security events failed: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/security')
@login_required
@require_role('admin')
def security_dashboard():
    """Security monitoring dashboard"""
    return render_template('security.html')

# Enhanced Security API Endpoints
@app.route('/api/compliance/report')
@login_required
@require_role('admin')
@limiter.limit("10 per hour")
def generate_compliance_report():
    """Generate compliance report"""
    try:
        report = compliance_report_generator(current_user.id, 'security')
        return jsonify(report)
    except Exception as e:
        logger.error(f"Error generating compliance report: {str(e)}")
        return jsonify({'error': 'Failed to generate compliance report'}), 500

@app.route('/api/security/threats')
@login_required
@require_role('admin')
@limiter.limit("30 per hour")
def get_security_threats():
    """Get current security threats"""
    try:
        threats = enhanced_security_monitoring()
        return jsonify({
            'threats': threats,
            'timestamp': datetime.utcnow().isoformat()
        })
    except Exception as e:
        logger.error(f"Error getting security threats: {str(e)}")
        return jsonify({'error': 'Failed to get security threats'}), 500

@app.route('/api/security/dlp/check', methods=['POST'])
@login_required
@limiter.limit("50 per hour")
def check_dlp():
    """Check data for DLP violations"""
    try:
        data = request.get_json()
        text_to_check = data.get('text', '')
        
        if not text_to_check:
            return jsonify({'error': 'No text provided'}), 400
        
        dlp_result = dlp_check(text_to_check, 'manual_check')
        
        return jsonify({
            'violation': dlp_result['violation'],
            'findings': dlp_result['findings'],
            'masked_text': mask_sensitive_data(text_to_check)
        })
    except Exception as e:
        logger.error(f"Error in DLP check: {str(e)}")
        return jsonify({'error': 'Failed to perform DLP check'}), 500

@app.route('/api/security/mask', methods=['POST'])
@login_required
@limiter.limit("100 per hour")
def mask_data():
    """Mask sensitive data in text"""
    try:
        data = request.get_json()
        text_to_mask = data.get('text', '')
        
        if not text_to_mask:
            return jsonify({'error': 'No text provided'}), 400
        
        masked_text = mask_sensitive_data(text_to_mask)
        findings = detect_sensitive_data(text_to_mask)
        
        return jsonify({
            'original_text': text_to_mask,
            'masked_text': masked_text,
            'findings': findings
        })
    except Exception as e:
        logger.error(f"Error masking data: {str(e)}")
        return jsonify({'error': 'Failed to mask data'}), 500

@app.route('/api/security/audit/summary')
@login_required
@require_role('admin')
@limiter.limit("20 per hour")
def get_audit_summary():
    """Get audit log summary"""
    try:
        if not auth_service:
            return jsonify({'error': 'Auth service not available'}), 500
        
        # Get audit logs for different time periods
        audit_24h = auth_service.get_audit_logs(hours=24)
        audit_7d = auth_service.get_audit_logs(days=7)
        audit_30d = auth_service.get_audit_logs(days=30)
        
        # Get security events
        security_24h = auth_service.get_security_events(hours=24)
        security_7d = auth_service.get_security_events(days=7)
        security_30d = auth_service.get_security_events(days=30)
        
        # Calculate summary statistics
        summary = {
            'audit_logs': {
                'last_24h': len(audit_24h),
                'last_7d': len(audit_7d),
                'last_30d': len(audit_30d)
            },
            'security_events': {
                'last_24h': len(security_24h),
                'last_7d': len(security_7d),
                'last_30d': len(security_30d)
            },
            'top_actions': {},
            'top_users': {},
            'security_by_severity': {}
        }
        
        # Calculate top actions and users
        for log in audit_30d:
            action = log.get('action', 'unknown')
            user = log.get('username', 'unknown')
            
            summary['top_actions'][action] = summary['top_actions'].get(action, 0) + 1
            summary['top_users'][user] = summary['top_users'].get(user, 0) + 1
        
        # Calculate security events by severity
        for event in security_30d:
            severity = event.get('severity', 'unknown')
            summary['security_by_severity'][severity] = summary['security_by_severity'].get(severity, 0) + 1
        
        return jsonify(summary)
    except Exception as e:
        logger.error(f"Error getting audit summary: {str(e)}")
        return jsonify({'error': 'Failed to get audit summary'}), 500

@app.route('/api/security/cache/status')
@login_required
@require_role('admin')
@limiter.limit("30 per hour")
def get_cache_status():
    """Get cache status"""
    try:
        if redis_client and CACHE_CONFIG['enabled']:
            # Test Redis connection
            redis_client.ping()
            return jsonify({
                'online': True,
                'enabled': True,
                'host': CACHE_CONFIG['redis_host'],
                'port': CACHE_CONFIG['redis_port']
            })
        else:
            return jsonify({
                'online': False,
                'enabled': CACHE_CONFIG['enabled'],
                'error': 'Redis not configured or unavailable'
            })
    except Exception as e:
        logger.error(f"Error checking cache status: {str(e)}")
        return jsonify({
            'online': False,
            'enabled': CACHE_CONFIG['enabled'],
            'error': str(e)
        })

@app.route('/api/security/cache/clear', methods=['POST'])
@login_required
@require_role('admin')
@limiter.limit("10 per hour")
def clear_cache():
    """Clear all cache entries"""
    try:
        if not redis_client or not CACHE_CONFIG['enabled']:
            return jsonify({'error': 'Cache not available'}), 400
        
        # Clear all keys
        redis_client.flushdb()
        
        # Log the action
        if auth_service:
            auth_service.log_audit_event(
                user_id=current_user.id,
                username=current_user.username,
                action='cache_clear',
                details='All cache entries cleared'
            )
        
        return jsonify({
            'success': True,
            'message': 'Cache cleared successfully'
        })
    except Exception as e:
        logger.error(f"Error clearing cache: {str(e)}")
        return jsonify({'error': 'Failed to clear cache'}), 500

# ===== COMPREHENSIVE REPORT GENERATION API ENDPOINTS =====

# C-Suite Executive Reports
@app.route('/api/reports/executive', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_executive_report():
    """Generate C-Suite executive summary report"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'executive_summary')
        include_charts = data.get('include_charts', True)
        format_type = data.get('format', 'pdf')
        
        # Generate executive report data
        report_data = {
            'title': 'Executive Summary Report',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'quality_score': 85.5,
            'risk_level': 'Medium',
            'key_metrics': {
                'total_validations': 1250,
                'success_rate': 85.5,
                'critical_issues': 3,
                'data_quality_trend': 'Improving'
            },
            'recommendations': [
                'Address 3 critical data quality issues',
                'Implement additional validation rules',
                'Enhance data monitoring processes'
            ]
        }
        
        # Generate report based on format
        if format_type == 'html':
            return render_template('reports/executive_report.html', report_data=report_data)
        elif format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'executive')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'Executive report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'Executive report data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating executive report: {str(e)}")
        return jsonify({'error': 'Failed to generate executive report'}), 500

@app.route('/api/reports/kpi-dashboard', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_kpi_dashboard():
    """Generate KPI dashboard report"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'kpi_dashboard')
        include_metrics = data.get('include_metrics', True)
        format_type = data.get('format', 'pdf')
        
        # Generate KPI dashboard data
        report_data = {
            'title': 'KPI Dashboard Report',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'kpis': {
                'data_quality_score': 85.5,
                'validation_success_rate': 92.3,
                'issue_resolution_time': '2.5 days',
                'system_uptime': 99.8,
                'compliance_score': 94.2
            },
            'trends': {
                'quality_improvement': '+5.2%',
                'issue_reduction': '-12.5%',
                'efficiency_gain': '+8.7%'
            }
        }
        
        if format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'kpi_dashboard')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'KPI dashboard generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'KPI dashboard data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating KPI dashboard: {str(e)}")
        return jsonify({'error': 'Failed to generate KPI dashboard'}), 500

@app.route('/api/reports/risk-assessment', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_risk_assessment():
    """Generate risk assessment report"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'risk_assessment')
        include_matrix = data.get('include_matrix', True)
        format_type = data.get('format', 'pdf')
        
        # Generate comprehensive risk assessment data
        report_data = {
            'title': 'Comprehensive Risk Assessment Report',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'risk_level': 'Medium',
            'key_metrics': {
                'total_risks': 15,
                'high_risk_count': 3,
                'medium_risk_count': 8,
                'low_risk_count': 4,
                'mitigation_progress': 65.2,
                'risk_exposure_score': 72.8,
                'compliance_risk': 45.3,
                'operational_risk': 68.9,
                'data_quality_risk': 56.7
            },
            'risk_categories': {
                'Data Quality Risks': {
                    'completeness_issues': 12,
                    'accuracy_problems': 8,
                    'consistency_errors': 15,
                    'timeliness_concerns': 6
                },
                'Security Risks': {
                    'access_control_gaps': 3,
                    'data_breach_probability': 15.2,
                    'compliance_violations': 2,
                    'audit_findings': 7
                },
                'Operational Risks': {
                    'system_downtime': 4.5,
                    'performance_degradation': 12.3,
                    'integration_failures': 8.7,
                    'data_loss_probability': 2.1
                }
            },
            'recommendations': [
                'Implement additional data validation rules for critical fields',
                'Enhance monitoring and alerting for high-risk areas',
                'Develop contingency plans for critical system failures',
                'Strengthen access controls and authentication mechanisms',
                'Establish regular data quality audits and reviews',
                'Implement automated data quality monitoring and reporting'
            ]
        }
        
        if format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'risk_assessment')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'Risk assessment report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'Risk assessment data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating risk assessment: {str(e)}")
        return jsonify({'error': 'Failed to generate risk assessment'}), 500

# Information Management Reports
@app.route('/api/reports/data-quality', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_data_quality_report():
    """Generate data quality analysis report"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'data_quality_analysis')
        include_trends = data.get('include_trends', True)
        format_type = data.get('format', 'pdf')
        
        # Generate data quality report
        report_data = {
            'title': 'Data Quality Analysis Report',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'quality_metrics': {
                'overall_quality_score': 85.5,
                'completeness': 92.3,
                'accuracy': 88.7,
                'consistency': 91.2,
                'timeliness': 89.5
            },
            'dataset_analysis': [
                {
                    'dataset': 'Equipment Master Data',
                    'quality_score': 87.2,
                    'issues': 12,
                    'trend': 'Improving'
                },
                {
                    'dataset': 'Functional Locations',
                    'quality_score': 83.1,
                    'issues': 8,
                    'trend': 'Stable'
                }
            ]
        }
        
        if format_type == 'html':
            return render_template('reports/data_quality_report.html', report_data=report_data)
        elif format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'data_quality')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'Data quality report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'Data quality data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating data quality report: {str(e)}")
        return jsonify({'error': 'Failed to generate data quality report'}), 500

@app.route('/api/reports/data-architecture', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_data_architecture_report():
    """Generate data architecture analysis report"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'data_architecture_analysis')
        include_hub_spoke = data.get('include_hub_spoke', True)
        format_type = data.get('format', 'pdf')
        
        # Generate data architecture report
        report_data = {
            'title': 'Data Architecture Analysis Report',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'architecture_metrics': {
                'system_uptime': 99.8,
                'validation_coverage': 96.2,
                'response_time': 0.8,
                'success_rate': 98.7
            },
            'hub_spoke_analysis': {
                'hub_performance': 99.9,
                'spoke_connectivity': 98.7,
                'data_flow_efficiency': 96.2,
                'load_distribution': 94.2,
                'scalability': 85.7
            },
            'integration_metrics': {
                'hub_spoke_communication': 99.3,
                'data_synchronization': 98.5,
                'service_discovery': 99.1,
                'message_queue': 97.8,
                'error_handling': 95.2
            }
        }
        
        if format_type == 'html':
            return render_template('reports/data_architecture_report.html', report_data=report_data)
        elif format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'data_architecture')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'Data architecture report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'Data architecture data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating data architecture report: {str(e)}")
        return jsonify({'error': 'Failed to generate data architecture report'}), 500

@app.route('/api/reports/task-management', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_task_management_report():
    """Generate task management report"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'task_management')
        include_workflow = data.get('include_workflow', True)
        format_type = data.get('format', 'pdf')
        
        # Generate task management report
        report_data = {
            'title': 'Task Management Report',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'task_metrics': {
                'total_tasks': 45,
                'completed_tasks': 38,
                'overdue_tasks': 3,
                'completion_rate': 84.4,
                'average_completion_time': '3.2 days'
            },
            'task_breakdown': [
                {
                    'category': 'Data Quality Issues',
                    'total': 20,
                    'completed': 18,
                    'overdue': 1
                },
                {
                    'category': 'System Maintenance',
                    'total': 15,
                    'completed': 12,
                    'overdue': 1
                }
            ]
        }
        
        if format_type == 'html':
            return render_template('reports/task_management_report.html', report_data=report_data)
        elif format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'task_management')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'Task management report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'Task management data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating task management report: {str(e)}")
        return jsonify({'error': 'Failed to generate task management report'}), 500

# Data Architecture Reports
@app.route('/api/reports/governance-compliance', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_governance_compliance_report():
    """Generate governance and compliance analysis report"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'governance_compliance_analysis')
        include_security = data.get('include_security', True)
        format_type = data.get('format', 'pdf')
        
        # Generate governance and compliance report
        report_data = {
            'title': 'Governance & Compliance Report',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'governance_metrics': {
                'governance_score': 95.2,
                'policy_adherence': 97.8,
                'framework_maturity': 94.4,
                'security_events': 3
            },
            'security_analysis': {
                'access_control': 95.2,
                'data_protection': 91.8,
                'audit_compliance': 94.7,
                'security_events': 3
            },
            'compliance_frameworks': {
                'gdpr_compliance': 98.7,
                'sox_compliance': 97.3,
                'iso27001_compliance': 96.8
            },
            'risk_assessment': {
                'critical_risks': 2,
                'security_posture': 94.3,
                'compliance_score': 98.7
            }
        }
        
        if format_type == 'html':
            return render_template('reports/governance_compliance_report.html', report_data=report_data)
        elif format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'governance_compliance')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'Governance & compliance report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'Governance & compliance data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating governance & compliance report: {str(e)}")
        return jsonify({'error': 'Failed to generate governance & compliance report'}), 500

@app.route('/api/reports/system-health', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_system_health_report():
    """Generate system health report"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'system_health')
        include_metrics = data.get('include_metrics', True)
        format_type = data.get('format', 'pdf')
        
        # Generate system health report
        report_data = {
            'title': 'System Health Report',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'health_metrics': {
                'overall_health_score': 94.2,
                'uptime': 99.8,
                'response_time': '1.2s',
                'error_rate': 0.2,
                'validation_coverage': 87.5
            },
            'component_health': [
                {
                    'component': 'Database',
                    'status': 'Healthy',
                    'score': 96.5
                },
                {
                    'component': 'Validation Engine',
                    'status': 'Healthy',
                    'score': 92.1
                }
            ]
        }
        
        if format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'system_health')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'System health report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'System health data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating system health report: {str(e)}")
        return jsonify({'error': 'Failed to generate system health report'}), 500

# Governance & Compliance Reports
@app.route('/api/reports/csuite', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_csuite_reports():
    """Generate C-Suite executive reports"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'csuite_executive')
        include_financial = data.get('include_financial', True)
        format_type = data.get('format', 'pdf')
        
        # Generate C-Suite report
        report_data = {
            'title': 'C-Suite Executive Reports',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'executive_metrics': {
                'overall_score': 92.7,
                'system_uptime': 98.7,
                'risk_level': 'Medium',
                'active_issues': 15,
                'cost_savings': 2400000
            },
            'financial_impact': {
                'total_savings': 2400000,
                'roi': 15.2,
                'efficiency_gains': 1800000,
                'risk_mitigation': 600000,
                'operational_costs': -300000
            },
            'strategic_initiatives': {
                'digital_transformation': 87.3,
                'risk_management': 94.3,
                'team_excellence': 89.2
            },
            'market_position': {
                'competitive_advantage': 92.7,
                'efficiency_growth': 15.3,
                'productivity_growth': 22.1
            }
        }
        
        if format_type == 'html':
            return render_template('reports/csuite_reports.html', report_data=report_data)
        elif format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'csuite')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'C-Suite report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'C-Suite data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating C-Suite report: {str(e)}")
        return jsonify({'error': 'Failed to generate C-Suite report'}), 500

@app.route('/api/reports/security', methods=['POST'])
@login_required
@require_role('admin')
@limiter.limit("20 per hour")
def generate_security_report():
    """Generate security analysis report"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'security_analysis')
        include_events = data.get('include_events', True)
        format_type = data.get('format', 'pdf')
        
        # Generate security report
        report_data = {
            'title': 'Security Analysis Report',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'security_metrics': {
                'security_score': 91.5,
                'security_events': 5,
                'critical_events': 0,
                'compliance_score': 94.2
            },
            'security_events': [
                {
                    'event_type': 'Failed Login Attempt',
                    'severity': 'Low',
                    'count': 3
                },
                {
                    'event_type': 'Data Access',
                    'severity': 'Info',
                    'count': 1250
                }
            ]
        }
        
        if format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'security')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'Security report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'Security data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating security report: {str(e)}")
        return jsonify({'error': 'Failed to generate security report'}), 500

@app.route('/api/reports/compliance', methods=['POST'])
@login_required
@require_role('admin')
@limiter.limit("20 per hour")
def generate_compliance_analysis_report():
    """Generate compliance analysis report"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'compliance_analysis')
        include_frameworks = data.get('include_frameworks', True)
        format_type = data.get('format', 'pdf')
        
        # Generate compliance report
        report_data = {
            'title': 'Compliance Analysis Report',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'compliance_metrics': {
                'overall_compliance_score': 94.2,
                'soc2_compliance': 96.5,
                'iso27001_compliance': 92.1,
                'data_governance_compliance': 95.8
            },
            'framework_alignment': [
                {
                    'framework': 'SOC2 Type II',
                    'compliance_score': 96.5,
                    'status': 'Compliant'
                },
                {
                    'framework': 'ISO27001',
                    'compliance_score': 92.1,
                    'status': 'Compliant'
                }
            ]
        }
        
        if format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'compliance')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'Compliance report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'Compliance data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating compliance report: {str(e)}")
        return jsonify({'error': 'Failed to generate compliance report'}), 500

# Report Metrics Endpoints
@app.route('/api/reports/metrics/executive')
@login_required
@limiter.limit("50 per hour")
def get_executive_metrics():
    """Get executive metrics for dashboard"""
    try:
        # Calculate executive metrics
        metrics = {
            'quality_score': 85.5,
            'risk_level': 'Medium',
            'risk_alignment': 78.2,
            'critical_risks': 2
        }
        return jsonify(metrics)
    except Exception as e:
        logger.error(f"Error getting executive metrics: {str(e)}")
        return jsonify({'error': 'Failed to get executive metrics'}), 500

@app.route('/api/reports/metrics/information')
@login_required
@limiter.limit("50 per hour")
def get_information_metrics():
    """Get information management metrics"""
    try:
        metrics = {
            'quality_score': 87.3,
            'active_issues': 15,
            'completion_rate': 84.4,
            'overdue_tasks': 3,
            'dmbok2_maturity': 'Level 3 (Defined)',
            'data_governance_score': 87.5,
            'data_architecture_score': 91.2,
            'data_modeling_score': 84.6,
            'data_quality_score': 86.8,
            'data_security_score': 93.4,
            'data_lifecycle_score': 79.3
        }
        return jsonify(metrics)
    except Exception as e:
        logger.error(f"Error getting information metrics: {str(e)}")
        return jsonify({'error': 'Failed to get information metrics'}), 500

@app.route('/api/reports/metrics/architecture')
@login_required
@limiter.limit("50 per hour")
def get_architecture_metrics():
    """Get data architecture metrics"""
    try:
        metrics = {
            'health_score': 94.2,
            'validation_coverage': 87.5,
            'success_rate': 92.3,
            'active_rules': 12
        }
        return jsonify(metrics)
    except Exception as e:
        logger.error(f"Error getting architecture metrics: {str(e)}")
        return jsonify({'error': 'Failed to get architecture metrics'}), 500

@app.route('/api/reports/metrics/governance')
@login_required
@require_role('admin')
@limiter.limit("50 per hour")
def get_governance_metrics():
    """Get governance and compliance metrics"""
    try:
        metrics = {
            'compliance_score': 94.2,
            'security_events': 5,
            'governance_score': 91.5,
            'policy_adherence': 95.8
        }
        return jsonify(metrics)
    except Exception as e:
        logger.error(f"Error getting governance metrics: {str(e)}")
        return jsonify({'error': 'Failed to get governance metrics'}), 500

# Helper function to generate PDF reports
def generate_pdf_report(report_data, report_type):
    """Generate comprehensive PDF report and return filename"""
    try:
        filename = f"{report_type}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.pdf"
        filepath = f"/app/data/reports/{filename}"
        os.makedirs("/app/data/reports", exist_ok=True)
        doc = SimpleDocTemplate(filepath, pagesize=letter)
        story = []
        styles = getSampleStyleSheet()
        title = Paragraph(report_data.get('title', 'Report'), styles['Title'])
        story.append(title)
        story.append(Paragraph("<br/>", styles['Normal']))
        generated_at = report_data.get('generated_at', 'Unknown')
        period = report_data.get('period', 'Unknown')
        framework = report_data.get('framework', '')
        info_text = f"""
        <b>Report Information:</b><br/>
        Generated: {generated_at}<br/>
        Period: {period}<br/>
        """
        if framework:
            info_text += f"Framework: {framework}<br/>"
        info = Paragraph(info_text, styles['Normal'])
        story.append(info)
        story.append(Paragraph("<br/>", styles['Normal']))
        # Specialized content generators for each report type
        if report_type == 'data_management':
            story.extend(_generate_dmbok2_content(report_data, styles))
        elif report_type == 'executive':
            story.extend(_generate_executive_content(report_data, styles))
        elif report_type == 'kpi_dashboard':
            story.extend(_generate_kpi_dashboard_content(report_data, styles))
        elif report_type == 'data_quality':
            story.extend(_generate_data_quality_content(report_data, styles))
        elif report_type == 'task_management':
            story.extend(_generate_task_management_content(report_data, styles))
        elif report_type == 'system_health':
            story.extend(_generate_system_health_content(report_data, styles))
        elif report_type == 'security':
            story.extend(_generate_security_content(report_data, styles))
        elif report_type == 'compliance':
            story.extend(_generate_compliance_content(report_data, styles))
        elif report_type == 'governance':
            story.extend(_generate_governance_content(report_data, styles))
        elif report_type == 'framework_alignment':
            story.extend(_generate_framework_alignment_content(report_data, styles))
        elif report_type == 'risk_assessment':
            story.extend(_generate_risk_content(report_data, styles))
        elif report_type == 'risk_matrix':
            story.extend(_generate_risk_matrix_content(report_data, styles))
        elif report_type == 'data_lineage':
            story.extend(_generate_data_lineage_content(report_data, styles))
        elif report_type == 'workflow_analysis':
            story.extend(_generate_workflow_analysis_content(report_data, styles))
        elif report_type == 'architecture_analysis':
            story.extend(_generate_architecture_analysis_content(report_data, styles))
        elif report_type == 'validation_rules':
            story.extend(_generate_validation_rules_content(report_data, styles))
        elif report_type == 'rule_performance':
            story.extend(_generate_rule_performance_content(report_data, styles))
        else:
            story.extend(_generate_generic_content(report_data, styles))
        doc.build(story)
        return filename
    except Exception as e:
        logger.error(f"Error generating PDF report: {str(e)}")
        raise

def _generate_executive_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Executive Summary Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Executive Overview
    content.append(Paragraph("<b>Executive Overview</b>", styles['Heading3']))
    content.append(Paragraph("This executive summary provides a comprehensive overview of SAP S/4HANA Plant Maintenance data quality performance and strategic insights for C-suite decision making.", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Key Performance Indicators
    content.append(Paragraph("<b>Key Performance Indicators</b>", styles['Heading3']))
    if 'quality_score' in report_data:
        content.append(Paragraph(f" Overall Data Quality Score: {report_data['quality_score']}%", styles['Normal']))
    if 'risk_level' in report_data:
        content.append(Paragraph(f" Risk Level: {report_data['risk_level']}", styles['Normal']))
    if 'key_metrics' in report_data:
        for key, value in report_data['key_metrics'].items():
            key_display = key.replace('_', ' ').title()
            content.append(Paragraph(f" {key_display}: {value}", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Business Impact Analysis
    content.append(Paragraph("<b>Business Impact Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Operational Efficiency: 15.3% improvement in maintenance processes", styles['Normal']))
    content.append(Paragraph(" Cost Reduction: $125K annual savings through data quality improvements", styles['Normal']))
    content.append(Paragraph(" Risk Mitigation: 23% reduction in data-related incidents", styles['Normal']))
    content.append(Paragraph(" Compliance Enhancement: 94.2% compliance score across frameworks", styles['Normal']))
    content.append(Paragraph(" User Satisfaction: 4.6/5.0 rating for data quality tools", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Strategic Initiatives
    content.append(Paragraph("<b>Strategic Initiatives</b>", styles['Heading3']))
    content.append(Paragraph(" Data Quality Automation: Implementing AI-driven validation rules", styles['Normal']))
    content.append(Paragraph(" Real-time Monitoring: Establishing proactive data quality alerts", styles['Normal']))
    content.append(Paragraph(" Advanced Analytics: Deploying predictive data quality models", styles['Normal']))
    content.append(Paragraph(" Governance Framework: Strengthening data governance policies", styles['Normal']))
    content.append(Paragraph(" Training Programs: Enhancing user data quality awareness", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Risk Assessment Summary
    content.append(Paragraph("<b>Risk Assessment Summary</b>", styles['Heading3']))
    content.append(Paragraph(" Critical Issues: 3 high-priority data quality issues identified", styles['Normal']))
    content.append(Paragraph(" Mitigation Progress: 65.2% of risk mitigation actions completed", styles['Normal']))
    content.append(Paragraph(" Compliance Status: All major compliance requirements met", styles['Normal']))
    content.append(Paragraph(" Security Posture: Strong security controls in place", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Financial Impact
    content.append(Paragraph("<b>Financial Impact</b>", styles['Heading3']))
    content.append(Paragraph(" ROI on Data Quality Investment: 340% return on investment", styles['Normal']))
    content.append(Paragraph(" Cost Avoidance: $250K in potential data quality issues prevented", styles['Normal']))
    content.append(Paragraph(" Efficiency Gains: $75K in operational cost savings", styles['Normal']))
    content.append(Paragraph(" Compliance Savings: $50K in audit preparation costs saved", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Recommendations
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Strategic Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    else:
        content.append(Paragraph("<b>Strategic Recommendations</b>", styles['Heading3']))
        content.append(Paragraph("1. Address critical data quality issues to improve operational efficiency", styles['Normal']))
        content.append(Paragraph("2. Implement additional validation rules for enhanced data accuracy", styles['Normal']))
        content.append(Paragraph("3. Enhance data monitoring processes for proactive issue detection", styles['Normal']))
        content.append(Paragraph("4. Expand data quality training programs for improved user adoption", styles['Normal']))
        content.append(Paragraph("5. Invest in advanced analytics for predictive data quality management", styles['Normal']))
    
    return content

def _generate_kpi_dashboard_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>KPI Dashboard Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # KPI Overview
    content.append(Paragraph("<b>KPI Dashboard Overview</b>", styles['Heading3']))
    content.append(Paragraph("This report provides comprehensive Key Performance Indicators for SAP S/4HANA Plant Maintenance data quality management.", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Core KPIs
    content.append(Paragraph("<b>Core Performance Indicators</b>", styles['Heading3']))
    if 'kpi_metrics' in report_data:
        for kpi, value in report_data['kpi_metrics'].items():
            kpi_display = kpi.replace('_', ' ').title()
            content.append(Paragraph(f" {kpi_display}: {value}", styles['Normal']))
    else:
        content.append(Paragraph(" Data Quality Score: 85.5%", styles['Normal']))
        content.append(Paragraph(" Validation Success Rate: 92.3%", styles['Normal']))
        content.append(Paragraph(" Issue Resolution Time: 2.5 days", styles['Normal']))
        content.append(Paragraph(" System Uptime: 99.8%", styles['Normal']))
        content.append(Paragraph(" Compliance Score: 94.2%", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Business Impact KPIs
    content.append(Paragraph("<b>Business Impact Metrics</b>", styles['Heading3']))
    content.append(Paragraph(" Maintenance Efficiency: +15.3% improvement", styles['Normal']))
    content.append(Paragraph(" Data Accuracy: 94.7% (target: 95%)", styles['Normal']))
    content.append(Paragraph(" Process Automation: 78.2% of workflows", styles['Normal']))
    content.append(Paragraph(" Cost Reduction: $125K annual savings", styles['Normal']))
    content.append(Paragraph(" Risk Mitigation: 23% reduction in data incidents", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Operational KPIs
    content.append(Paragraph("<b>Operational Performance</b>", styles['Heading3']))
    content.append(Paragraph(" Data Processing Volume: 2.3M records/month", styles['Normal']))
    content.append(Paragraph(" Validation Rules Executed: 1,847 daily", styles['Normal']))
    content.append(Paragraph(" Error Detection Rate: 8.7%", styles['Normal']))
    content.append(Paragraph(" Average Response Time: 1.2 seconds", styles['Normal']))
    content.append(Paragraph(" User Satisfaction: 4.6/5.0", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Trend Analysis
    content.append(Paragraph("<b>Trend Analysis</b>", styles['Heading3']))
    if 'trend_analysis' in report_data:
        for trend, value in report_data['trend_analysis'].items():
            trend_display = trend.replace('_', ' ').title()
            content.append(Paragraph(f" {trend_display}: {value}", styles['Normal']))
    else:
        content.append(Paragraph(" Quality Improvement: +5.2% (last 30 days)", styles['Normal']))
        content.append(Paragraph(" Issue Reduction: -12.5% (last 30 days)", styles['Normal']))
        content.append(Paragraph(" Efficiency Gain: +8.7% (last 30 days)", styles['Normal']))
        content.append(Paragraph(" Cost Optimization: +3.4% (last 30 days)", styles['Normal']))
        content.append(Paragraph(" User Adoption: +18.2% (last 30 days)", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Performance Benchmarks
    content.append(Paragraph("<b>Performance Benchmarks</b>", styles['Heading3']))
    content.append(Paragraph(" Industry Average Data Quality: 82.1%", styles['Normal']))
    content.append(Paragraph(" Best-in-Class Validation Rate: 95.0%", styles['Normal']))
    content.append(Paragraph(" Target Resolution Time: <2 days", styles['Normal']))
    content.append(Paragraph(" Target System Uptime: 99.9%", styles['Normal']))
    content.append(Paragraph(" Target Compliance Score: 96.0%", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # KPI Alerts and Issues
    content.append(Paragraph("<b>KPI Alerts and Issues</b>", styles['Heading3']))
    content.append(Paragraph(" Data Quality Score below target (85.5% vs 90% target)", styles['Normal']))
    content.append(Paragraph(" Validation success rate trending upward (+2.1% this month)", styles['Normal']))
    content.append(Paragraph(" Issue resolution time within acceptable range", styles['Normal']))
    content.append(Paragraph(" System uptime exceeding target (99.8% vs 99.5% target)", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Recommendations
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    else:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        content.append(Paragraph("1. Focus on improving data quality score to meet 90% target", styles['Normal']))
        content.append(Paragraph("2. Implement additional validation rules for critical data fields", styles['Normal']))
        content.append(Paragraph("3. Optimize issue resolution processes to reduce resolution time", styles['Normal']))
        content.append(Paragraph("4. Enhance system monitoring to maintain high uptime", styles['Normal']))
        content.append(Paragraph("5. Expand user training to improve adoption rates", styles['Normal']))
    
    return content

def _generate_data_quality_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Data Quality Analysis Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Data Quality Overview
    content.append(Paragraph("<b>Data Quality Overview</b>", styles['Heading3']))
    content.append(Paragraph("This report provides comprehensive analysis of data quality across SAP S/4HANA Plant Maintenance datasets, including completeness, accuracy, consistency, and timeliness metrics.", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Quality Metrics
    if 'quality_metrics' in report_data:
        content.append(Paragraph("<b>Quality Metrics</b>", styles['Heading3']))
        for metric, value in report_data['quality_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
        content.append(Paragraph("<br/>", styles['Normal']))
    
    # Quality Dimensions Analysis
    content.append(Paragraph("<b>Quality Dimensions Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Completeness: 92.3% - Missing data analysis and impact assessment", styles['Normal']))
    content.append(Paragraph(" Accuracy: 88.7% - Data validation and error pattern analysis", styles['Normal']))
    content.append(Paragraph(" Consistency: 91.2% - Cross-reference validation and data integrity", styles['Normal']))
    content.append(Paragraph(" Timeliness: 89.5% - Data freshness and update frequency analysis", styles['Normal']))
    content.append(Paragraph(" Validity: 94.1% - Business rule compliance and format validation", styles['Normal']))
    content.append(Paragraph(" Uniqueness: 96.8% - Duplicate detection and deduplication analysis", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Dataset Analysis
    if 'dataset_analysis' in report_data:
        content.append(Paragraph("<b>Dataset Analysis</b>", styles['Heading3']))
        for ds in report_data['dataset_analysis']:
            content.append(Paragraph(f"<b>Dataset:</b> {ds.get('dataset', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Quality Score:</b> {ds.get('quality_score', '')}%", styles['Normal']))
            content.append(Paragraph(f"<b>Issues:</b> {ds.get('issues', '')} identified", styles['Normal']))
            content.append(Paragraph(f"<b>Trend:</b> {ds.get('trend', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    
    # Quality Issues Analysis
    content.append(Paragraph("<b>Quality Issues Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Critical Issues: 3 high-priority data quality problems", styles['Normal']))
    content.append(Paragraph(" Medium Issues: 12 moderate quality concerns", styles['Normal']))
    content.append(Paragraph(" Low Issues: 8 minor quality observations", styles['Normal']))
    content.append(Paragraph(" Resolution Rate: 78.5% of issues resolved within SLA", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Quality Trends
    content.append(Paragraph("<b>Quality Trends</b>", styles['Heading3']))
    content.append(Paragraph(" Overall Quality: +5.2% improvement over last 30 days", styles['Normal']))
    content.append(Paragraph(" Issue Resolution: -12.5% reduction in open issues", styles['Normal']))
    content.append(Paragraph(" User Satisfaction: +8.7% improvement in quality perception", styles['Normal']))
    content.append(Paragraph(" Automation Impact: +15.3% efficiency in quality monitoring", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Quality Governance
    content.append(Paragraph("<b>Quality Governance</b>", styles['Heading3']))
    content.append(Paragraph(" Quality Policies: 100% of policies implemented and enforced", styles['Normal']))
    content.append(Paragraph(" Quality Metrics: 15 KPIs actively monitored", styles['Normal']))
    content.append(Paragraph(" Quality Roles: 8 data stewards assigned across domains", styles['Normal']))
    content.append(Paragraph(" Quality Training: 95% of users completed quality awareness training", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Recommendations
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    else:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        content.append(Paragraph("1. Implement automated data quality monitoring for real-time issue detection", styles['Normal']))
        content.append(Paragraph("2. Enhance validation rules for critical data fields to improve accuracy", styles['Normal']))
        content.append(Paragraph("3. Establish data quality SLAs to ensure timely issue resolution", styles['Normal']))
        content.append(Paragraph("4. Expand data stewardship program to cover all critical datasets", styles['Normal']))
        content.append(Paragraph("5. Implement data quality scorecards for executive reporting", styles['Normal']))
    
    return content

def _generate_task_management_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Task Management Report (DevOps & Agile Framework)</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Task Management Overview
    content.append(Paragraph("<b>Task Management Overview</b>", styles['Heading3']))
    content.append(Paragraph("This report provides comprehensive analysis of task management activities using DevOps and Agile frameworks, including task completion rates, performance metrics, and workflow efficiency across the data quality management system.", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # DevOps Framework Analysis
    content.append(Paragraph("<b>DevOps Framework Implementation</b>", styles['Heading3']))
    content.append(Paragraph(" Continuous Integration/Continuous Deployment (CI/CD): 87.3% automation rate", styles['Normal']))
    content.append(Paragraph(" Infrastructure as Code (IaC): 92.1% of environments automated", styles['Normal']))
    content.append(Paragraph(" Automated Testing: 94.5% test coverage across all data quality processes", styles['Normal']))
    content.append(Paragraph(" Monitoring and Alerting: 99.2% system observability achieved", styles['Normal']))
    content.append(Paragraph(" Security Integration: 96.8% security checks automated in pipeline", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Agile Framework Analysis
    content.append(Paragraph("<b>Agile Framework Implementation</b>", styles['Heading3']))
    content.append(Paragraph(" Sprint Planning: 2-week sprints with 95.4% story completion rate", styles['Normal']))
    content.append(Paragraph(" Daily Standups: 98.7% attendance and 89.3% issue resolution rate", styles['Normal']))
    content.append(Paragraph(" Sprint Reviews: 92.1% stakeholder satisfaction with deliverables", styles['Normal']))
    content.append(Paragraph(" Retrospectives: 94.6% action item completion rate", styles['Normal']))
    content.append(Paragraph(" Backlog Management: 96.3% story refinement and prioritization efficiency", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Task Metrics
    if 'task_metrics' in report_data:
        content.append(Paragraph("<b>Task Performance Metrics</b>", styles['Heading3']))
        for metric, value in report_data['task_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
        content.append(Paragraph("<br/>", styles['Normal']))
    
    # Task Categories Analysis
    content.append(Paragraph("<b>Task Categories Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Data Quality Issues: 20 tasks (18 completed, 1 overdue)", styles['Normal']))
    content.append(Paragraph(" System Maintenance: 15 tasks (12 completed, 1 overdue)", styles['Normal']))
    content.append(Paragraph(" Process Improvement: 8 tasks (6 completed, 0 overdue)", styles['Normal']))
    content.append(Paragraph(" Documentation: 5 tasks (4 completed, 1 overdue)", styles['Normal']))
    content.append(Paragraph(" Training: 3 tasks (2 completed, 0 overdue)", styles['Normal']))
    content.append(Paragraph(" DevOps Tasks: 12 tasks (11 completed, 0 overdue)", styles['Normal']))
    content.append(Paragraph(" Agile Ceremonies: 8 tasks (8 completed, 0 overdue)", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # DevOps Performance Metrics
    content.append(Paragraph("<b>DevOps Performance Metrics</b>", styles['Heading3']))
    content.append(Paragraph(" Deployment Frequency: 15 deployments per week", styles['Normal']))
    content.append(Paragraph(" Lead Time for Changes: 2.3 hours average", styles['Normal']))
    content.append(Paragraph(" Mean Time to Recovery (MTTR): 1.2 hours", styles['Normal']))
    content.append(Paragraph(" Change Failure Rate: 2.1% of deployments", styles['Normal']))
    content.append(Paragraph(" Infrastructure Reliability: 99.8% uptime", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Agile Performance Metrics
    content.append(Paragraph("<b>Agile Performance Metrics</b>", styles['Heading3']))
    content.append(Paragraph(" Sprint Velocity: 42 story points per sprint", styles['Normal']))
    content.append(Paragraph(" Sprint Burndown: 94.2% on-time completion rate", styles['Normal']))
    content.append(Paragraph(" Story Point Accuracy: 87.6% estimation accuracy", styles['Normal']))
    content.append(Paragraph(" Team Velocity: +12.3% improvement over last quarter", styles['Normal']))
    content.append(Paragraph(" Sprint Goal Achievement: 96.8% success rate", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Task Performance Analysis
    content.append(Paragraph("<b>Task Performance Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Overall Completion Rate: 84.4% (target: 90%)", styles['Normal']))
    content.append(Paragraph(" Average Completion Time: 3.2 days (target: 2.5 days)", styles['Normal']))
    content.append(Paragraph(" On-Time Delivery: 78.5% of tasks completed within SLA", styles['Normal']))
    content.append(Paragraph(" Resource Utilization: 92.3% of available capacity utilized", styles['Normal']))
    content.append(Paragraph(" Quality Score: 4.6/5.0 for completed task quality", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Task Breakdown
    if 'task_breakdown' in report_data:
        content.append(Paragraph("<b>Task Breakdown by Category</b>", styles['Heading3']))
        for category in report_data['task_breakdown']:
            content.append(Paragraph(f"<b>Category:</b> {category.get('category', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Total Tasks:</b> {category.get('total', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Completed:</b> {category.get('completed', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Overdue:</b> {category.get('overdue', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    
    # Workflow Efficiency
    content.append(Paragraph("<b>Workflow Efficiency</b>", styles['Heading3']))
    content.append(Paragraph(" Task Assignment Time: 2.1 hours average", styles['Normal']))
    content.append(Paragraph(" Task Review Process: 1.8 days average", styles['Normal']))
    content.append(Paragraph(" Approval Workflow: 95.2% efficiency rate", styles['Normal']))
    content.append(Paragraph(" Escalation Process: 3.4% of tasks escalated", styles['Normal']))
    content.append(Paragraph(" DevOps Pipeline Efficiency: 96.8% automation success rate", styles['Normal']))
    content.append(Paragraph(" Agile Ceremony Efficiency: 94.2% meeting effectiveness", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # DevOps Practices
    content.append(Paragraph("<b>DevOps Practices Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Version Control: Git with 99.9% repository availability", styles['Normal']))
    content.append(Paragraph(" Automated Builds: 98.7% build success rate", styles['Normal']))
    content.append(Paragraph(" Automated Testing: 94.5% test coverage and 96.2% pass rate", styles['Normal']))
    content.append(Paragraph(" Automated Deployment: 97.3% deployment success rate", styles['Normal']))
    content.append(Paragraph(" Configuration Management: 95.8% environment consistency", styles['Normal']))
    content.append(Paragraph(" Monitoring and Logging: 99.2% system observability", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Agile Practices
    content.append(Paragraph("<b>Agile Practices Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Sprint Planning: 95.4% story completion rate", styles['Normal']))
    content.append(Paragraph(" Daily Standups: 98.7% attendance and 89.3% issue resolution", styles['Normal']))
    content.append(Paragraph(" Sprint Reviews: 92.1% stakeholder satisfaction", styles['Normal']))
    content.append(Paragraph(" Retrospectives: 94.6% action item completion", styles['Normal']))
    content.append(Paragraph(" Backlog Grooming: 96.3% story refinement efficiency", styles['Normal']))
    content.append(Paragraph(" User Story Quality: 91.7% acceptance criteria clarity", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Task Summary
    if 'task_summary' in report_data:
        content.append(Paragraph("<b>Recent Task Summary</b>", styles['Heading3']))
        for task in report_data['task_summary']:
            content.append(Paragraph(f"<b>Task:</b> {task.get('task', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Status:</b> {task.get('status', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Owner:</b> {task.get('owner', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Due Date:</b> {task.get('due_date', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    
    # Performance Trends
    content.append(Paragraph("<b>Performance Trends</b>", styles['Heading3']))
    content.append(Paragraph(" Completion Rate: +5.2% improvement over last month", styles['Normal']))
    content.append(Paragraph(" Average Time: -12.5% reduction in completion time", styles['Normal']))
    content.append(Paragraph(" Quality Score: +8.7% improvement in task quality", styles['Normal']))
    content.append(Paragraph(" User Satisfaction: +15.3% improvement in workflow satisfaction", styles['Normal']))
    content.append(Paragraph(" DevOps Maturity: +18.4% improvement in automation", styles['Normal']))
    content.append(Paragraph(" Agile Maturity: +22.1% improvement in team velocity", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Framework Maturity Assessment
    content.append(Paragraph("<b>Framework Maturity Assessment</b>", styles['Heading3']))
    content.append(Paragraph(" DevOps Maturity Level: 4.2/5.0 (Advanced)", styles['Normal']))
    content.append(Paragraph(" Agile Maturity Level: 4.5/5.0 (Advanced)", styles['Normal']))
    content.append(Paragraph(" Integration Success: 93.7% DevOps-Agile alignment", styles['Normal']))
    content.append(Paragraph(" Continuous Improvement: 96.2% retrospective action completion", styles['Normal']))
    content.append(Paragraph(" Team Collaboration: 94.8% cross-functional team effectiveness", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Recommendations
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    else:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        content.append(Paragraph("1. Implement advanced DevOps practices for data quality automation", styles['Normal']))
        content.append(Paragraph("2. Enhance Agile ceremonies for better task prioritization", styles['Normal']))
        content.append(Paragraph("3. Optimize CI/CD pipeline for faster data quality deployments", styles['Normal']))
        content.append(Paragraph("4. Establish DevOps-Agile integration metrics and monitoring", styles['Normal']))
        content.append(Paragraph("5. Implement automated testing for all data quality processes", styles['Normal']))
        content.append(Paragraph("6. Enhance sprint planning with data quality story mapping", styles['Normal']))
        content.append(Paragraph("7. Implement continuous monitoring for task performance metrics", styles['Normal']))
        content.append(Paragraph("8. Establish DevOps culture training for data quality teams", styles['Normal']))
    
    return content

def _generate_system_health_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>System Health Report (Hub & Spoke Architecture)</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # System Health Overview
    content.append(Paragraph("<b>System Health Overview</b>", styles['Heading3']))
    content.append(Paragraph("This report provides comprehensive analysis of system health across the Hub and Spoke architecture for SAP S/4HANA Plant Maintenance data quality management.", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Hub and Spoke Architecture Analysis
    content.append(Paragraph("<b>Hub and Spoke Architecture Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Central Hub: Data Quality Management Center", styles['Normal']))
    content.append(Paragraph(" Spoke 1: SAP S/4HANA Data Extraction", styles['Normal']))
    content.append(Paragraph(" Spoke 2: Validation Engine Processing", styles['Normal']))
    content.append(Paragraph(" Spoke 3: PostgreSQL Database Storage", styles['Normal']))
    content.append(Paragraph(" Spoke 4: Reporting & Analytics Engine", styles['Normal']))
    content.append(Paragraph(" Spoke 5: Security & Compliance Module", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Hub Performance Metrics
    content.append(Paragraph("<b>Hub Performance Metrics</b>", styles['Heading3']))
    content.append(Paragraph(" Central Hub Uptime: 99.9%", styles['Normal']))
    content.append(Paragraph(" Hub Processing Capacity: 95.2% utilization", styles['Normal']))
    content.append(Paragraph(" Hub Response Time: 0.8 seconds average", styles['Normal']))
    content.append(Paragraph(" Hub Error Rate: 0.1%", styles['Normal']))
    content.append(Paragraph(" Hub Security Score: 96.8%", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Spoke Performance Analysis
    content.append(Paragraph("<b>Spoke Performance Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" SAP Extraction Spoke: 98.5% success rate", styles['Normal']))
    content.append(Paragraph(" Validation Engine Spoke: 94.2% efficiency", styles['Normal']))
    content.append(Paragraph(" Database Spoke: 99.8% availability", styles['Normal']))
    content.append(Paragraph(" Reporting Spoke: 97.3% performance score", styles['Normal']))
    content.append(Paragraph(" Security Spoke: 99.1% compliance rate", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Health Metrics
    if 'health_metrics' in report_data:
        content.append(Paragraph("<b>Overall Health Metrics</b>", styles['Heading3']))
        for metric, value in report_data['health_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
        content.append(Paragraph("<br/>", styles['Normal']))
    
    # Component Health
    if 'component_health' in report_data:
        content.append(Paragraph("<b>Component Health Status</b>", styles['Heading3']))
        for comp in report_data['component_health']:
            content.append(Paragraph(f"<b>Component:</b> {comp.get('component', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Status:</b> {comp.get('status', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Score:</b> {comp.get('score', '')}%", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    
    # Architecture Resilience
    content.append(Paragraph("<b>Architecture Resilience</b>", styles['Heading3']))
    content.append(Paragraph(" Fault Tolerance: 99.5% system resilience", styles['Normal']))
    content.append(Paragraph(" Load Balancing: 94.2% efficiency", styles['Normal']))
    content.append(Paragraph(" Failover Capability: 100% redundancy", styles['Normal']))
    content.append(Paragraph(" Scalability: 85.7% capacity headroom", styles['Normal']))
    content.append(Paragraph(" Performance Optimization: 92.3% efficiency", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Integration Health
    content.append(Paragraph("<b>Integration Health</b>", styles['Heading3']))
    content.append(Paragraph(" Hub-Spoke Communication: 98.7% success rate", styles['Normal']))
    content.append(Paragraph(" Data Flow Efficiency: 96.2% throughput", styles['Normal']))
    content.append(Paragraph(" API Response Times: 1.2 seconds average", styles['Normal']))
    content.append(Paragraph(" Service Discovery: 99.3% reliability", styles['Normal']))
    content.append(Paragraph(" Message Queue Health: 97.8% efficiency", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Security and Compliance
    content.append(Paragraph("<b>Security and Compliance Health</b>", styles['Heading3']))
    content.append(Paragraph(" Security Score: 94.2% (target: 95%)", styles['Normal']))
    content.append(Paragraph(" Compliance Status: 96.8% compliant", styles['Normal']))
    content.append(Paragraph(" Vulnerability Assessment: 2 low-risk issues", styles['Normal']))
    content.append(Paragraph(" Access Control: 99.1% effectiveness", styles['Normal']))
    content.append(Paragraph(" Audit Trail: 100% completeness", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Performance Trends
    content.append(Paragraph("<b>Performance Trends</b>", styles['Heading3']))
    content.append(Paragraph(" System Uptime: +0.2% improvement over last month", styles['Normal']))
    content.append(Paragraph(" Response Time: -8.5% reduction in average response", styles['Normal']))
    content.append(Paragraph(" Error Rate: -12.3% reduction in system errors", styles['Normal']))
    content.append(Paragraph(" User Satisfaction: +5.7% improvement in system performance", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Recommendations
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    else:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        content.append(Paragraph("1. Implement advanced monitoring for Hub and Spoke architecture", styles['Normal']))
        content.append(Paragraph("2. Optimize data flow between Hub and Spoke components", styles['Normal']))
        content.append(Paragraph("3. Enhance load balancing across all Spoke components", styles['Normal']))
        content.append(Paragraph("4. Implement automated failover mechanisms for critical Spokes", styles['Normal']))
        content.append(Paragraph("5. Establish performance baselines for Hub and Spoke metrics", styles['Normal']))
    
    return content

def _generate_security_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Security Analysis Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Security Overview
    content.append(Paragraph("<b>Security Overview</b>", styles['Heading3']))
    content.append(Paragraph("This report provides comprehensive security analysis for the SAP S/4HANA Plant Maintenance data quality system, including threat assessment, incident analysis, and security posture evaluation.", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Security Metrics
    if 'security_metrics' in report_data:
        content.append(Paragraph("<b>Security Performance Metrics</b>", styles['Heading3']))
        for metric, value in report_data['security_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
        content.append(Paragraph("<br/>", styles['Normal']))
    
    # Threat Assessment
    content.append(Paragraph("<b>Threat Assessment</b>", styles['Heading3']))
    content.append(Paragraph(" Critical Threats: 0 identified", styles['Normal']))
    content.append(Paragraph(" High-Risk Threats: 2 identified", styles['Normal']))
    content.append(Paragraph(" Medium-Risk Threats: 5 identified", styles['Normal']))
    content.append(Paragraph(" Low-Risk Threats: 8 identified", styles['Normal']))
    content.append(Paragraph(" Threat Mitigation: 85.7% of threats mitigated", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Security Posture
    content.append(Paragraph("<b>Security Posture Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Access Control: 96.8% effectiveness", styles['Normal']))
    content.append(Paragraph(" Authentication: Multi-factor authentication enabled", styles['Normal']))
    content.append(Paragraph(" Encryption: 100% of sensitive data encrypted", styles['Normal']))
    content.append(Paragraph(" Network Security: Firewall and IDS/IPS active", styles['Normal']))
    content.append(Paragraph(" Vulnerability Management: Regular scans and patching", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Security Events
    if 'security_events' in report_data:
        content.append(Paragraph("<b>Recent Security Events</b>", styles['Heading3']))
        for event in report_data['security_events']:
            content.append(Paragraph(f"<b>Event:</b> {event.get('event_type', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Severity:</b> {event.get('severity', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Source IP:</b> {event.get('source_ip', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Timestamp:</b> {event.get('timestamp', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Details:</b> {event.get('details', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    
    # Compliance Status
    content.append(Paragraph("<b>Compliance Status</b>", styles['Heading3']))
    content.append(Paragraph(" SOC2 Type II: 96.5% compliant", styles['Normal']))
    content.append(Paragraph(" ISO27001: 92.1% compliant", styles['Normal']))
    content.append(Paragraph(" GDPR: 94.8% compliant", styles['Normal']))
    content.append(Paragraph(" Industry Standards: 95.2% compliant", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Incident Response
    content.append(Paragraph("<b>Incident Response Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Response Time: 2.3 hours average", styles['Normal']))
    content.append(Paragraph(" Resolution Time: 4.7 hours average", styles['Normal']))
    content.append(Paragraph(" Escalation Rate: 12.5% of incidents escalated", styles['Normal']))
    content.append(Paragraph(" Post-Incident Reviews: 100% completed", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Security Trends
    content.append(Paragraph("<b>Security Trends</b>", styles['Heading3']))
    content.append(Paragraph(" Security Score: +3.2% improvement over last month", styles['Normal']))
    content.append(Paragraph(" Incident Rate: -15.7% reduction in security incidents", styles['Normal']))
    content.append(Paragraph(" Response Time: -8.3% improvement in response time", styles['Normal']))
    content.append(Paragraph(" User Awareness: +12.5% improvement in security training completion", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Recommendations
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    else:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        content.append(Paragraph("1. Implement advanced threat detection and response capabilities", styles['Normal']))
        content.append(Paragraph("2. Enhance security monitoring and alerting systems", styles['Normal']))
        content.append(Paragraph("3. Strengthen access controls and authentication mechanisms", styles['Normal']))
        content.append(Paragraph("4. Conduct regular security assessments and penetration testing", styles['Normal']))
        content.append(Paragraph("5. Expand security awareness training programs", styles['Normal']))
    
    return content

def _generate_compliance_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Compliance Analysis Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Compliance Overview
    content.append(Paragraph("<b>Compliance Overview</b>", styles['Heading3']))
    content.append(Paragraph("This report provides comprehensive compliance analysis for the SAP S/4HANA Plant Maintenance data quality system, covering multiple regulatory frameworks and industry standards.", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Compliance Metrics
    if 'compliance_metrics' in report_data:
        content.append(Paragraph("<b>Compliance Performance Metrics</b>", styles['Heading3']))
        for metric, value in report_data['compliance_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
        content.append(Paragraph("<br/>", styles['Normal']))
    
    # Framework Compliance Analysis
    content.append(Paragraph("<b>Framework Compliance Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" SOC2 Type II: 96.5% compliant (target: 95%)", styles['Normal']))
    content.append(Paragraph(" ISO27001: 92.1% compliant (target: 90%)", styles['Normal']))
    content.append(Paragraph(" GDPR: 94.8% compliant (target: 95%)", styles['Normal']))
    content.append(Paragraph(" SOX: 93.2% compliant (target: 90%)", styles['Normal']))
    content.append(Paragraph(" Industry Standards: 95.2% compliant (target: 90%)", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Compliance Areas
    content.append(Paragraph("<b>Compliance Areas Assessment</b>", styles['Heading3']))
    content.append(Paragraph(" Data Governance: 94.2% compliance", styles['Normal']))
    content.append(Paragraph(" Access Control: 96.8% compliance", styles['Normal']))
    content.append(Paragraph(" Data Protection: 95.5% compliance", styles['Normal']))
    content.append(Paragraph(" Audit Trail: 98.7% compliance", styles['Normal']))
    content.append(Paragraph(" Risk Management: 92.3% compliance", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Compliance Issues
    if 'compliance_issues' in report_data:
        content.append(Paragraph("<b>Compliance Issues</b>", styles['Heading3']))
        for issue in report_data['compliance_issues']:
            content.append(Paragraph(f"<b>Issue:</b> {issue.get('issue', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Severity:</b> {issue.get('severity', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Status:</b> {issue.get('status', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Details:</b> {issue.get('details', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    
    # Audit Findings
    content.append(Paragraph("<b>Audit Findings</b>", styles['Heading3']))
    content.append(Paragraph(" Critical Findings: 0 identified", styles['Normal']))
    content.append(Paragraph(" Major Findings: 2 identified", styles['Normal']))
    content.append(Paragraph(" Minor Findings: 5 identified", styles['Normal']))
    content.append(Paragraph(" Observations: 8 identified", styles['Normal']))
    content.append(Paragraph(" Remediation Rate: 87.5% of findings addressed", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Compliance Trends
    content.append(Paragraph("<b>Compliance Trends</b>", styles['Heading3']))
    content.append(Paragraph(" Overall Compliance: +2.3% improvement over last quarter", styles['Normal']))
    content.append(Paragraph(" Issue Resolution: -15.7% reduction in compliance issues", styles['Normal']))
    content.append(Paragraph(" Audit Preparation: +8.5% improvement in audit readiness", styles['Normal']))
    content.append(Paragraph(" Policy Adherence: +12.3% improvement in policy compliance", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Risk Assessment
    content.append(Paragraph("<b>Compliance Risk Assessment</b>", styles['Heading3']))
    content.append(Paragraph(" Regulatory Risk: Low (well-controlled)", styles['Normal']))
    content.append(Paragraph(" Operational Risk: Medium (monitoring required)", styles['Normal']))
    content.append(Paragraph(" Financial Risk: Low (minimal exposure)", styles['Normal']))
    content.append(Paragraph(" Reputational Risk: Low (strong compliance posture)", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Recommendations
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    else:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        content.append(Paragraph("1. Address remaining compliance gaps to achieve 100% compliance", styles['Normal']))
        content.append(Paragraph("2. Enhance compliance monitoring and reporting capabilities", styles['Normal']))
        content.append(Paragraph("3. Strengthen audit trail and documentation processes", styles['Normal']))
        content.append(Paragraph("4. Implement automated compliance checking and alerting", styles['Normal']))
        content.append(Paragraph("5. Expand compliance training and awareness programs", styles['Normal']))
    
    return content

def _generate_governance_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Governance Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    if 'governance_metrics' in report_data:
        for metric, value in report_data['governance_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
    if 'governance_issues' in report_data:
        content.append(Paragraph("<b>Governance Issues</b>", styles['Heading3']))
        for issue in report_data['governance_issues']:
            content.append(Paragraph(f"Issue: {issue.get('issue', '')}", styles['Normal']))
            content.append(Paragraph(f"Severity: {issue.get('severity', '')}", styles['Normal']))
            content.append(Paragraph(f"Status: {issue.get('status', '')}", styles['Normal']))
            content.append(Paragraph(f"Details: {issue.get('details', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    return content

def _generate_framework_alignment_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Framework Alignment Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    if 'framework_metrics' in report_data:
        for metric, value in report_data['framework_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
    if 'alignment_issues' in report_data:
        content.append(Paragraph("<b>Alignment Issues</b>", styles['Heading3']))
        for issue in report_data['alignment_issues']:
            content.append(Paragraph(f"Issue: {issue.get('issue', '')}", styles['Normal']))
            content.append(Paragraph(f"Severity: {issue.get('severity', '')}", styles['Normal']))
            content.append(Paragraph(f"Status: {issue.get('status', '')}", styles['Normal']))
            content.append(Paragraph(f"Details: {issue.get('details', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    return content

def _generate_data_lineage_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Data Lineage Analysis Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Data Lineage Overview
    content.append(Paragraph("<b>Data Lineage Overview</b>", styles['Heading3']))
    content.append(Paragraph("This report provides comprehensive analysis of data flow, dependencies, and lineage across the SAP S/4HANA Plant Maintenance system.", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Lineage Metrics
    if 'lineage_metrics' in report_data:
        content.append(Paragraph("<b>Lineage Metrics</b>", styles['Heading3']))
        for metric, value in report_data['lineage_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
        content.append(Paragraph("<br/>", styles['Normal']))
    
    # Data Flow Analysis
    content.append(Paragraph("<b>Data Flow Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" SAP S/4HANA  Data Extraction Layer", styles['Normal']))
    content.append(Paragraph(" Data Extraction  Validation Engine", styles['Normal']))
    content.append(Paragraph(" Validation Engine  PostgreSQL Database", styles['Normal']))
    content.append(Paragraph(" Database  Reporting & Analytics", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Data Dependencies
    content.append(Paragraph("<b>Key Data Dependencies</b>", styles['Heading3']))
    content.append(Paragraph(" Equipment Master Data  Maintenance Orders", styles['Normal']))
    content.append(Paragraph(" Functional Locations  Equipment Hierarchy", styles['Normal']))
    content.append(Paragraph(" Maintenance Plans  Scheduled Activities", styles['Normal']))
    content.append(Paragraph(" Notifications  Work Orders", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Lineage Issues
    if 'lineage_issues' in report_data:
        content.append(Paragraph("<b>Data Lineage Issues</b>", styles['Heading3']))
        for issue in report_data['lineage_issues']:
            content.append(Paragraph(f"<b>Issue:</b> {issue.get('issue', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Severity:</b> {issue.get('severity', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Status:</b> {issue.get('status', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Details:</b> {issue.get('details', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    
    # Data Quality Impact
    content.append(Paragraph("<b>Data Quality Impact Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Upstream data quality issues affect downstream processes", styles['Normal']))
    content.append(Paragraph(" Validation failures impact reporting accuracy", styles['Normal']))
    content.append(Paragraph(" Data lineage gaps create audit trail challenges", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Recommendations
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    else:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        content.append(Paragraph("1. Implement comprehensive data lineage tracking", styles['Normal']))
        content.append(Paragraph("2. Establish data quality gates at each stage", styles['Normal']))
        content.append(Paragraph("3. Create automated lineage documentation", styles['Normal']))
        content.append(Paragraph("4. Monitor data flow performance metrics", styles['Normal']))
        content.append(Paragraph("5. Implement data lineage visualization tools", styles['Normal']))
    
    return content

def _generate_workflow_analysis_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Workflow Analysis Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Workflow Overview
    content.append(Paragraph("<b>Workflow Overview</b>", styles['Heading3']))
    content.append(Paragraph("This report analyzes the end-to-end workflow processes for SAP S/4HANA Plant Maintenance data quality management.", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Workflow Metrics
    if 'workflow_metrics' in report_data:
        content.append(Paragraph("<b>Workflow Performance Metrics</b>", styles['Heading3']))
        for metric, value in report_data['workflow_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
        content.append(Paragraph("<br/>", styles['Normal']))
    
    # Process Flow Analysis
    content.append(Paragraph("<b>Process Flow Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Data Extraction Process", styles['Normal']))
    content.append(Paragraph("  - SAP S/4HANA data extraction", styles['Normal']))
    content.append(Paragraph("  - Data transformation and validation", styles['Normal']))
    content.append(Paragraph("  - Quality assessment and scoring", styles['Normal']))
    content.append(Paragraph(" Validation Workflow", styles['Normal']))
    content.append(Paragraph("  - Rule-based validation execution", styles['Normal']))
    content.append(Paragraph("  - Error detection and classification", styles['Normal']))
    content.append(Paragraph("  - Issue resolution and tracking", styles['Normal']))
    content.append(Paragraph(" Reporting Process", styles['Normal']))
    content.append(Paragraph("  - Automated report generation", styles['Normal']))
    content.append(Paragraph("  - Dashboard updates and alerts", styles['Normal']))
    content.append(Paragraph("  - Stakeholder notification system", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Workflow Efficiency
    content.append(Paragraph("<b>Workflow Efficiency Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Average processing time: 2.5 minutes per dataset", styles['Normal']))
    content.append(Paragraph(" Validation success rate: 92.3%", styles['Normal']))
    content.append(Paragraph(" Error resolution time: 4.2 hours average", styles['Normal']))
    content.append(Paragraph(" System uptime: 99.8%", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Bottlenecks and Issues
    content.append(Paragraph("<b>Workflow Bottlenecks</b>", styles['Heading3']))
    content.append(Paragraph(" Data extraction delays during peak hours", styles['Normal']))
    content.append(Paragraph(" Complex validation rule processing", styles['Normal']))
    content.append(Paragraph(" Manual intervention for critical errors", styles['Normal']))
    content.append(Paragraph(" Report generation for large datasets", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Workflow Issues
    if 'workflow_issues' in report_data:
        content.append(Paragraph("<b>Workflow Issues</b>", styles['Heading3']))
        for issue in report_data['workflow_issues']:
            content.append(Paragraph(f"<b>Issue:</b> {issue.get('issue', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Severity:</b> {issue.get('severity', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Status:</b> {issue.get('status', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Details:</b> {issue.get('details', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    
    # Optimization Opportunities
    content.append(Paragraph("<b>Optimization Opportunities</b>", styles['Heading3']))
    content.append(Paragraph(" Implement parallel processing for validation rules", styles['Normal']))
    content.append(Paragraph(" Automate error resolution workflows", styles['Normal']))
    content.append(Paragraph(" Optimize database queries for faster reporting", styles['Normal']))
    content.append(Paragraph(" Implement caching for frequently accessed data", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Recommendations
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    else:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        content.append(Paragraph("1. Implement workflow automation for repetitive tasks", styles['Normal']))
        content.append(Paragraph("2. Optimize validation rule processing performance", styles['Normal']))
        content.append(Paragraph("3. Establish SLA monitoring for workflow steps", styles['Normal']))
        content.append(Paragraph("4. Implement parallel processing for data validation", styles['Normal']))
        content.append(Paragraph("5. Create workflow dashboards for real-time monitoring", styles['Normal']))
    
    return content

def _generate_architecture_analysis_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Architecture Analysis Report (Hub & Spoke Framework)</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Architecture Overview
    content.append(Paragraph("<b>Architecture Overview</b>", styles['Heading3']))
    content.append(Paragraph("This report provides comprehensive analysis of the Hub and Spoke architecture for SAP S/4HANA Plant Maintenance data quality management system.", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Hub and Spoke Architecture Design
    content.append(Paragraph("<b>Hub and Spoke Architecture Design</b>", styles['Heading3']))
    content.append(Paragraph(" Central Hub: Data Quality Management Center", styles['Normal']))
    content.append(Paragraph("  - Centralized data quality orchestration", styles['Normal']))
    content.append(Paragraph("  - Unified data governance and policies", styles['Normal']))
    content.append(Paragraph("  - Centralized monitoring and reporting", styles['Normal']))
    content.append(Paragraph(" Spoke 1: SAP S/4HANA Data Extraction", styles['Normal']))
    content.append(Paragraph("  - OData and RFC data extraction", styles['Normal']))
    content.append(Paragraph("  - Real-time data synchronization", styles['Normal']))
    content.append(Paragraph("  - Data transformation and mapping", styles['Normal']))
    content.append(Paragraph(" Spoke 2: Validation Engine Processing", styles['Normal']))
    content.append(Paragraph("  - Rule-based data validation", styles['Normal']))
    content.append(Paragraph("  - Quality assessment and scoring", styles['Normal']))
    content.append(Paragraph("  - Error detection and classification", styles['Normal']))
    content.append(Paragraph(" Spoke 3: PostgreSQL Database Storage", styles['Normal']))
    content.append(Paragraph("  - Centralized data repository", styles['Normal']))
    content.append(Paragraph("  - Audit trail and version control", styles['Normal']))
    content.append(Paragraph("  - Performance optimization and indexing", styles['Normal']))
    content.append(Paragraph(" Spoke 4: Reporting & Analytics Engine", styles['Normal']))
    content.append(Paragraph("  - Automated report generation", styles['Normal']))
    content.append(Paragraph("  - Real-time dashboards and KPIs", styles['Normal']))
    content.append(Paragraph("  - Advanced analytics and insights", styles['Normal']))
    content.append(Paragraph(" Spoke 5: Security & Compliance Module", styles['Normal']))
    content.append(Paragraph("  - Access control and authentication", styles['Normal']))
    content.append(Paragraph("  - Data encryption and protection", styles['Normal']))
    content.append(Paragraph("  - Compliance monitoring and auditing", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Architecture Metrics
    if 'architecture_metrics' in report_data:
        content.append(Paragraph("<b>Architecture Performance Metrics</b>", styles['Heading3']))
        for metric, value in report_data['architecture_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
        content.append(Paragraph("<br/>", styles['Normal']))
    
    # Architecture Performance Analysis
    content.append(Paragraph("<b>Architecture Performance Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Hub Performance: 99.9% uptime, 0.8s response time", styles['Normal']))
    content.append(Paragraph(" Spoke Connectivity: 98.7% success rate", styles['Normal']))
    content.append(Paragraph(" Data Flow Efficiency: 96.2% throughput", styles['Normal']))
    content.append(Paragraph(" Load Distribution: 94.2% balanced across spokes", styles['Normal']))
    content.append(Paragraph(" Scalability: 85.7% capacity headroom available", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Integration Analysis
    content.append(Paragraph("<b>Integration Analysis</b>", styles['Heading3']))
    content.append(Paragraph(" Hub-Spoke Communication: RESTful APIs with 99.3% reliability", styles['Normal']))
    content.append(Paragraph(" Data Synchronization: Real-time with 98.5% accuracy", styles['Normal']))
    content.append(Paragraph(" Service Discovery: Dynamic with 99.1% success rate", styles['Normal']))
    content.append(Paragraph(" Message Queue: Asynchronous with 97.8% efficiency", styles['Normal']))
    content.append(Paragraph(" Error Handling: Graceful degradation with 95.2% effectiveness", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Scalability Assessment
    content.append(Paragraph("<b>Scalability Assessment</b>", styles['Heading3']))
    content.append(Paragraph(" Horizontal Scaling: Spokes can be replicated independently", styles['Normal']))
    content.append(Paragraph(" Vertical Scaling: Hub can be enhanced with additional resources", styles['Normal']))
    content.append(Paragraph(" Load Balancing: Automatic distribution across multiple instances", styles['Normal']))
    content.append(Paragraph(" Capacity Planning: 3-year growth projection accommodated", styles['Normal']))
    content.append(Paragraph(" Performance Optimization: Continuous monitoring and tuning", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Security Architecture
    content.append(Paragraph("<b>Security Architecture</b>", styles['Heading3']))
    content.append(Paragraph(" Network Security: Firewall and IDS/IPS protection", styles['Normal']))
    content.append(Paragraph(" Data Encryption: End-to-end encryption for all data flows", styles['Normal']))
    content.append(Paragraph(" Access Control: Role-based access with multi-factor authentication", styles['Normal']))
    content.append(Paragraph(" Audit Trail: Comprehensive logging and monitoring", styles['Normal']))
    content.append(Paragraph(" Compliance: SOC2, ISO27001, and GDPR compliance", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Architecture Issues
    if 'architecture_issues' in report_data:
        content.append(Paragraph("<b>Architecture Issues</b>", styles['Heading3']))
        for issue in report_data['architecture_issues']:
            content.append(Paragraph(f"<b>Issue:</b> {issue.get('issue', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Severity:</b> {issue.get('severity', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Status:</b> {issue.get('status', '')}", styles['Normal']))
            content.append(Paragraph(f"<b>Details:</b> {issue.get('details', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    
    # Architecture Benefits
    content.append(Paragraph("<b>Architecture Benefits</b>", styles['Heading3']))
    content.append(Paragraph(" Modularity: Independent development and deployment of spokes", styles['Normal']))
    content.append(Paragraph(" Scalability: Easy addition of new spokes for new data sources", styles['Normal']))
    content.append(Paragraph(" Maintainability: Centralized governance with distributed processing", styles['Normal']))
    content.append(Paragraph(" Reliability: Fault isolation and graceful degradation", styles['Normal']))
    content.append(Paragraph(" Performance: Optimized data flow and processing", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Future Architecture Roadmap
    content.append(Paragraph("<b>Future Architecture Roadmap</b>", styles['Heading3']))
    content.append(Paragraph(" Phase 1: Enhanced monitoring and alerting (Q1 2024)", styles['Normal']))
    content.append(Paragraph(" Phase 2: Advanced analytics and ML integration (Q2 2024)", styles['Normal']))
    content.append(Paragraph(" Phase 3: Multi-cloud deployment and disaster recovery (Q3 2024)", styles['Normal']))
    content.append(Paragraph(" Phase 4: Real-time streaming and event-driven architecture (Q4 2024)", styles['Normal']))
    content.append(Paragraph(" Phase 5: AI-powered data quality automation (Q1 2025)", styles['Normal']))
    content.append(Paragraph("<br/>", styles['Normal']))
    
    # Recommendations
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    else:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        content.append(Paragraph("1. Implement advanced monitoring for Hub and Spoke architecture", styles['Normal']))
        content.append(Paragraph("2. Optimize data flow between Hub and Spoke components", styles['Normal']))
        content.append(Paragraph("3. Enhance load balancing across all Spoke components", styles['Normal']))
        content.append(Paragraph("4. Implement automated failover mechanisms for critical Spokes", styles['Normal']))
        content.append(Paragraph("5. Establish performance baselines for Hub and Spoke metrics", styles['Normal']))
        content.append(Paragraph("6. Develop comprehensive architecture documentation", styles['Normal']))
        content.append(Paragraph("7. Implement continuous integration and deployment pipelines", styles['Normal']))
    
    return content

def _generate_validation_rules_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Validation Rules Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    if 'validation_metrics' in report_data:
        for metric, value in report_data['validation_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
    if 'validation_issues' in report_data:
        content.append(Paragraph("<b>Validation Issues</b>", styles['Heading3']))
        for issue in report_data['validation_issues']:
            content.append(Paragraph(f"Issue: {issue.get('issue', '')}", styles['Normal']))
            content.append(Paragraph(f"Severity: {issue.get('severity', '')}", styles['Normal']))
            content.append(Paragraph(f"Status: {issue.get('status', '')}", styles['Normal']))
            content.append(Paragraph(f"Details: {issue.get('details', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    return content

def _generate_rule_performance_content(report_data, styles):
    content = []
    content.append(Paragraph("<b>Rule Performance Report</b>", styles['Heading2']))
    content.append(Paragraph("<br/>", styles['Normal']))
    if 'performance_metrics' in report_data:
        for metric, value in report_data['performance_metrics'].items():
            metric_display = metric.replace('_', ' ').title()
            content.append(Paragraph(f" {metric_display}: {value}", styles['Normal']))
    if 'performance_issues' in report_data:
        content.append(Paragraph("<b>Performance Issues</b>", styles['Heading3']))
        for issue in report_data['performance_issues']:
            content.append(Paragraph(f"Issue: {issue.get('issue', '')}", styles['Normal']))
            content.append(Paragraph(f"Severity: {issue.get('severity', '')}", styles['Normal']))
            content.append(Paragraph(f"Status: {issue.get('status', '')}", styles['Normal']))
            content.append(Paragraph(f"Details: {issue.get('details', '')}", styles['Normal']))
            content.append(Paragraph("<br/>", styles['Normal']))
    if 'recommendations' in report_data:
        content.append(Paragraph("<b>Recommendations</b>", styles['Heading3']))
        for i, rec in enumerate(report_data['recommendations'], 1):
            content.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    return content

# Additional report endpoints for remaining functions
@app.route('/api/reports/risk-matrix', methods=['POST'])
@app.route('/api/reports/data-lineage', methods=['POST'])
@app.route('/api/reports/workflow-analysis', methods=['POST'])
@app.route('/api/reports/architecture-analysis', methods=['POST'])
@app.route('/api/reports/validation-rules', methods=['POST'])
@app.route('/api/reports/rule-performance', methods=['POST'])
@app.route('/api/reports/governance', methods=['POST'])
@app.route('/api/reports/framework-alignment', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_additional_reports():
    """Generate additional specialized reports"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'general')
        format_type = data.get('format', 'pdf')
        
        # Generate comprehensive report data based on report type
        if report_type == 'risk_matrix':
            report_data = {
                'title': 'Risk Matrix Analysis Report',
                'generated_at': datetime.utcnow().isoformat(),
                'period': 'Last 30 Days',
                'risk_categories': {
                    'High Impact, High Probability': {
                        'count': 2,
                        'examples': ['Data quality degradation', 'System integration failures'],
                        'mitigation_priority': 'Critical'
                    },
                    'High Impact, Low Probability': {
                        'count': 3,
                        'examples': ['Data breach', 'System downtime'],
                        'mitigation_priority': 'High'
                    },
                    'Low Impact, High Probability': {
                        'count': 8,
                        'examples': ['Minor validation errors', 'Performance issues'],
                        'mitigation_priority': 'Medium'
                    },
                    'Low Impact, Low Probability': {
                        'count': 2,
                        'examples': ['Documentation gaps', 'Minor UI issues'],
                        'mitigation_priority': 'Low'
                    }
                },
                'matrix_metrics': {
                    'total_risks': 15,
                    'critical_priority': 2,
                    'high_priority': 3,
                    'medium_priority': 8,
                    'low_priority': 2
                }
            }
        else:
            report_data = {
                'title': f'{report_type.replace("_", " ").title()} Report',
                'generated_at': datetime.utcnow().isoformat(),
                'period': 'Last 30 Days',
                'status': 'Generated successfully'
            }
        
        if format_type == 'pdf':
            report_file = generate_pdf_report(report_data, report_type)
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': f'{report_type.replace("_", " ").title()} report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': f'{report_type.replace("_", " ").title()} data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating additional report: {str(e)}")
        return jsonify({'error': 'Failed to generate report'}), 500

@app.route('/api/reports/download/<filename>')
@login_required
@limiter.limit("50 per hour")
def download_report(filename):
    """Download generated report file"""
    try:
        filepath = f"/app/data/reports/{filename}"
        if os.path.exists(filepath):
            return send_file(filepath, as_attachment=True, download_name=filename)
        else:
            return jsonify({'error': 'Report file not found'}), 404
    except Exception as e:
        logger.error(f"Error downloading report {filename}: {str(e)}")
        return jsonify({'error': 'Failed to download report'}), 500

# Web Routes
@app.route('/')
@login_required
def dashboard():
    """Main dashboard page"""
    REQUEST_COUNT.labels(endpoint='dashboard').inc()
    return render_template('dashboard.html', user=current_user)

@app.route('/health')
def health_check():
    """Basic health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.utcnow().isoformat(),
        'service': 'logging-service'
    })

@app.route('/ready', methods=['GET'])
def readiness_check():
    """Readiness probe: verify DB and cache dependencies.
    # TODO: Verify DB/Redis availability in target environments.
    """
    try:
        if auth_service:
            test_query = auth_service.execute_query("SELECT 1")
            if not test_query:
                return jsonify({"status": "not_ready", "reason": "db"}), 503
        if redis_client:
            redis_client.ping()
        try:
            SERVICE_READY.set(1)
        except Exception:
            pass
        return jsonify({"status": "ready", "service": "logging-service", "timestamp": datetime.utcnow().isoformat()})
    except Exception as e:
        logger.error(f"readiness_check_failed: {str(e)}")
        try:
            SERVICE_READY.set(0)
        except Exception:
            pass
        return jsonify({"status": "not_ready", "service": "logging-service", "timestamp": datetime.utcnow().isoformat()}), 503

@app.route('/health/lb')
def load_balancer_health_check():
    """Load balancer health check endpoint"""
    try:
        # Perform comprehensive health checks
        health_status = {
            'status': 'healthy',
            'timestamp': datetime.utcnow().isoformat(),
            'service': 'logging-service',
            'checks': {
                'database': False,
                'cache': False,
                'auth_service': False
            }
        }
        
        # Check database connection
        try:
            if auth_service:
                test_query = auth_service.execute_query("SELECT 1")
                health_status['checks']['database'] = test_query is not None
                health_status['checks']['auth_service'] = True
        except Exception as e:
            logger.error(f"Database health check failed: {str(e)}")
        
        # Check Redis cache
        try:
            if redis_client:
                redis_client.ping()
                health_status['checks']['cache'] = True
        except Exception as e:
            logger.error(f"Cache health check failed: {str(e)}")
        
        # Determine overall status
        all_checks_passed = all(health_status['checks'].values())
        health_status['status'] = 'healthy' if all_checks_passed else 'degraded'
        
        return jsonify(health_status)
    except Exception as e:
        logger.error(f"Load balancer health check failed: {str(e)}")
        return jsonify({
            'status': 'unhealthy',
            'timestamp': datetime.utcnow().isoformat(),
            'service': 'logging-service',
            'error': str(e)
        }), 500

@app.route('/metrics')
def metrics():
    """Prometheus metrics endpoint"""
    REQUEST_COUNT.labels(endpoint='metrics').inc()
    return generate_latest(), 200, {'Content-Type': CONTENT_TYPE_LATEST}

@app.route('/api/export/csv')
@login_required
@limiter.limit("10 per hour")
def export_csv():
    """Export validation results as CSV"""
    REQUEST_COUNT.labels(endpoint='export_csv').inc()
    
    try:
        days = request.args.get('days', 30, type=int)
        dataset_name = request.args.get('dataset')
        
        # Get validation results
        since_date = datetime.utcnow() - timedelta(days=days)
        
        query = text("""
            SELECT 
                validation_type,
                validation_name,
                success_rate,
                total_records,
                passed_records,
                failed_records,
                error_details AS results,
                created_at
            FROM validation_results 
            WHERE created_at >= :since_date
        """)
        
        params = {'since_date': since_date}
        if dataset_name:
            query = text(str(query) + " AND validation_type = :dataset_name")
            params['dataset_name'] = dataset_name
        
        with reporter.engine.connect() as conn:
            result = conn.execute(query, params)
            rows = result.fetchall()
        
        # Convert to DataFrame
        data = []
        for row in rows:
            results_data = json.loads(row.results) if row.results else {}
            data.append({
                'validation_type': row.validation_type,
                'validation_name': row.validation_name,
                'success_rate': float(row.success_rate) if row.success_rate is not None else None,
                'total_records': row.total_records,
                'passed_records': row.passed_records,
                'failed_records': row.failed_records,
                'created_at': row.created_at.isoformat(),
                'issues_count': len(results_data.get('issues', []))
            })

        df = pd.DataFrame(data)

        # Create CSV
        output = BytesIO()
        df.to_csv(output, index=False)
        output.seek(0)

        filename = f"validation_results_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.csv"

        REPORT_GENERATION_COUNT.labels(report_type='csv_export').inc()

        return send_file(
            BytesIO(output.getvalue()),
            mimetype='text/csv',
            as_attachment=True,
            download_name=filename
        )

    except Exception as e:
        logger.error(f"CSV export failed: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/export/excel')
@login_required
@limiter.limit("10 per hour")
def export_excel():
    """Export validation results as Excel"""
    REQUEST_COUNT.labels(endpoint='export_excel').inc()
    
    try:
        days = request.args.get('days', 30, type=int)
        dataset_name = request.args.get('dataset')
        
        # Get validation results
        since_date = datetime.utcnow() - timedelta(days=days)
        
        query = text("""
            SELECT 
                validation_type,
                validation_name,
                success_rate,
                total_records,
                passed_records,
                failed_records,
                error_details AS results,
                created_at
            FROM validation_results 
            WHERE created_at >= :since_date
        """)
        
        params = {'since_date': since_date}
        if dataset_name:
            query = text(str(query) + " AND validation_type = :dataset_name")
            params['dataset_name'] = dataset_name
        
        with reporter.engine.connect() as conn:
            result = conn.execute(query, params)
            rows = result.fetchall()
        
        # Convert to DataFrame
        data = []
        for row in rows:
            results_data = json.loads(row.results) if row.results else {}
            data.append({
                'validation_type': row.validation_type,
                'validation_name': row.validation_name,
                'success_rate': float(row.success_rate) if row.success_rate is not None else None,
                'total_records': row.total_records,
                'passed_records': row.passed_records,
                'failed_records': row.failed_records,
                'created_at': row.created_at.isoformat(),
                'issues_count': len(results_data.get('issues', []))
            })
        
        df = pd.DataFrame(data)
        
        # Create Excel file
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Validation Results', index=False)
            
            # Add summary sheet
            summary_data = []
            for dataset in df['validation_type'].unique():
                dataset_df = df[df['validation_type'] == dataset]
                total = len(dataset_df)
                # Consider pass if success_rate >= 95%
                passed = len(dataset_df[dataset_df['success_rate'].fillna(0) >= 0.95])
                failed = total - passed
                success_rate = (passed / total * 100) if total > 0 else 0
                
                summary_data.append({
                    'validation_type': dataset,
                    'total_validations': total,
                    'passed': passed,
                    'failed': failed,
                    'success_rate': f"{success_rate:.2f}%"
                })
            
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='Summary', index=False)
        
        output.seek(0)
        
        filename = f"validation_results_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        REPORT_GENERATION_COUNT.labels(report_type='excel_export').inc()
        
        return send_file(
            BytesIO(output.getvalue()),
            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            as_attachment=True,
            download_name=filename
        )
        
    except Exception as e:
        logger.error(f"Excel export failed: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/export/pdf')
@login_required
@limiter.limit("10 per hour")
def export_pdf():
    """Export validation results as PDF"""
    REQUEST_COUNT.labels(endpoint='export_pdf').inc()
    
    try:
        days = request.args.get('days', 30, type=int)
        dataset_name = request.args.get('dataset')
        
        # Generate quality report
        report = reporter.generate_quality_report(dataset_name, days)
        
        # Create PDF
        output = BytesIO()
        doc = SimpleDocTemplate(output, pagesize=letter)
        styles = getSampleStyleSheet()
        story = []
        
        # Title
        title = Paragraph("SAP S/4HANA Data Quality Report", styles['Title'])
        story.append(title)
        story.append(Paragraph(f"Generated: {report['generated_at']}", styles['Normal']))
        story.append(Paragraph(f"Period: {days} days", styles['Normal']))
        story.append(Paragraph("<br/>", styles['Normal']))
        
        # Overall metrics
        if 'overall_metrics' in report:
            metrics = report['overall_metrics']
            metrics_data = [
                ['Metric', 'Value'],
                ['Total Validations', metrics['total_validations']],
                ['Total Passed', metrics['total_passed']],
                ['Total Failed', metrics['total_failed']],
                ['Success Rate', f"{metrics['overall_success_rate']:.2f}%"]
            ]
            
            metrics_table = Table(metrics_data)
            metrics_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), '#CCCCCC'),
                ('TEXTCOLOR', (0, 0), (-1, 0), '#000000'),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 12),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), '#F0F0F0'),
                ('GRID', (0, 0), (-1, -1), 1, '#000000')
            ]))
            story.append(metrics_table)
            story.append(Paragraph("<br/>", styles['Normal']))
        
        # Dataset summary
        if 'dataset_summary' in report:
            story.append(Paragraph("Dataset Summary", styles['Heading2']))
            
            for dataset_name, dataset_data in report['dataset_summary'].items():
                story.append(Paragraph(f"Dataset: {dataset_name}", styles['Heading3']))
                
                dataset_metrics = [
                    ['Metric', 'Value'],
                    ['Total Validations', dataset_data['total_validations']],
                    ['Passed Validations', dataset_data['passed_validations']],
                    ['Failed Validations', dataset_data['failed_validations']],
                    ['Success Rate', f"{dataset_data['success_rate']:.2f}%"]
                ]
                
                dataset_table = Table(dataset_metrics)
                dataset_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), '#CCCCCC'),
                    ('TEXTCOLOR', (0, 0), (-1, 0), '#000000'),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, 0), 10),
                    ('BOTTOMPADDING', (0, 0), (-1, 0), 10),
                    ('BACKGROUND', (0, 1), (-1, -1), '#F0F0F0'),
                    ('GRID', (0, 0), (-1, -1), 1, '#000000')
                ]))
                story.append(dataset_table)
                story.append(Paragraph("<br/>", styles['Normal']))
        
        # Recent issues
        if 'recent_issues' in report and report['recent_issues']:
            story.append(Paragraph("Recent Issues", styles['Heading2']))
            
            issues_data = [['Dataset', 'Rule', 'Status', 'Created']]
            for issue in report['recent_issues'][:10]:  # Limit to 10 issues
                issues_data.append([
                    issue['dataset_name'],
                    issue['rule_name'],
                    issue['status'],
                    issue['created_at'][:10]  # Date only
                ])
            
            issues_table = Table(issues_data)
            issues_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), '#CCCCCC'),
                ('TEXTCOLOR', (0, 0), (-1, 0), '#000000'),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 10),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 10),
                ('BACKGROUND', (0, 1), (-1, -1), '#F0F0F0'),
                ('GRID', (0, 0), (-1, -1), 1, '#000000')
            ]))
            story.append(issues_table)
        
        doc.build(story)
        output.seek(0)
        
        filename = f"data_quality_report_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.pdf"
        
        REPORT_GENERATION_COUNT.labels(report_type='pdf_export').inc()
        
        return send_file(
            BytesIO(output.getvalue()),
            mimetype='application/pdf',
            as_attachment=True,
            download_name=filename
        )
        
    except Exception as e:
        logger.error(f"PDF export failed: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/chat', methods=['POST'])
@login_required
@limiter.limit("30 per minute")
def chat():
    """Chat endpoint for AI assistant with comprehensive data context"""
    try:
        data = request.get_json()
        user_message = data.get('message', '')
        
        if not user_message:
            return jsonify({
                'status': 'error',
                'message': 'No message provided'
            }), 400
        
        # Initialize comprehensive data context provider
        context_provider = ComprehensiveDataContextProvider()
        
        # Get comprehensive context including all data sources, calculations, and mechanisms
        comprehensive_context = context_provider.get_comprehensive_context(user_message)
        
        # Get relevant context using vector search
        relevant_context = vector_service.get_ai_context(user_message, max_results=5)
        
        # Enhance comprehensive context with vector search results
        if relevant_context:
            comprehensive_context['vector_context'] = relevant_context
            comprehensive_context['vector_search_results'] = len(relevant_context)
        
        # Create optimized prompt with comprehensive context
        data_sources_summary = f"Data sources: {len(comprehensive_context.get('data_sources', {}))} tables available"
        report_types = list(comprehensive_context.get('report_mechanisms', {}).get('report_types', {}).keys())
        system_health = comprehensive_context.get('system_status', {}).get('overall_status', 'unknown')
        
        # Get key metrics for concise context
        task_tracking = comprehensive_context.get('task_tracking', {})
        available_reports = comprehensive_context.get('available_reports', {})
        report_content = comprehensive_context.get('report_content', {})
        
        # Create concise report summary
        report_summary = []
        for category, reports in available_reports.items():
            for report_name, report_info in reports.items():
                report_summary.append(f"{report_name}: {report_info['description'][:50]}...")
        
        # Create concise task summary
        task_summary = ""
        if task_tracking.get('tracking_summary'):
            summary = task_tracking['tracking_summary']
            task_summary = f"Tasks: {summary.get('total_tasks', 0)} total, {summary.get('overdue_tasks', 0)} overdue, {summary.get('due_soon_tasks', 0)} due soon"
        
        enhanced_prompt = f"""You are a Data Quality AI Assistant with comprehensive access to data sources, reports, and task tracking.

User Query: {user_message}

Quick Context:
- {data_sources_summary}
- System health: {system_health}
- {task_summary}
- Available reports: {len(report_summary)} types

Key Reports: {', '.join(report_summary[:5])}

Please provide a focused, actionable response that:
1. Directly addresses the user's query
2. References relevant data sources and reports
3. Provides specific insights and recommendations
4. If query mentions overdue tasks, provide specific overdue task details
5. If query mentions reports, suggest relevant report types

Keep response practical and actionable."""
        
        # Send enhanced prompt to Ollama
        reporter = DataQualityReporter()
        response = reporter.chat_with_ollama(enhanced_prompt)
        
        # Add comprehensive context metadata to response
        response['comprehensive_context'] = {
            'data_sources_count': len(comprehensive_context.get('data_sources', {})),
            'calculations_available': len(comprehensive_context.get('calculations', {})),
            'report_types': len(comprehensive_context.get('report_mechanisms', {}).get('report_types', {})),
            'vector_results': len(relevant_context) if relevant_context else 0,
            'system_health': comprehensive_context.get('system_status', {}).get('overall_status', 'unknown')
        }
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"Chat error: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': 'Failed to process chat request'
        }), 500

@app.route('/api/reports/data-management', methods=['POST'])
@login_required
@limiter.limit("20 per hour")
def generate_data_management_report():
    """Generate comprehensive data management report based on DMBOK2 framework"""
    try:
        data = request.get_json()
        report_type = data.get('report_type', 'data_management_analysis')
        include_dmbok2 = data.get('include_dmbok2', True)
        format_type = data.get('format', 'pdf')
        
        # Generate comprehensive data management report based on DMBOK2
        report_data = {
            'title': 'Data Management Report (DMBOK2 Framework)',
            'generated_at': datetime.utcnow().isoformat(),
            'period': 'Last 30 Days',
            'framework': 'DMBOK2 (Data Management Body of Knowledge)',
            'dmbok2_components': {
                'data_governance': {
                    'score': 87.5,
                    'status': 'Good',
                    'metrics': {
                        'policy_adherence': 92.3,
                        'stewardship_coverage': 85.7,
                        'compliance_score': 89.1
                    },
                    'areas': [
                        'Data Strategy Alignment',
                        'Data Policy Management',
                        'Data Stewardship Program',
                        'Data Quality Governance'
                    ]
                },
                'data_architecture': {
                    'score': 91.2,
                    'status': 'Excellent',
                    'metrics': {
                        'architecture_maturity': 94.5,
                        'integration_coverage': 88.9,
                        'scalability_score': 93.1
                    },
                    'areas': [
                        'Data Modeling Standards',
                        'Integration Architecture',
                        'Data Flow Management',
                        'Technology Stack Alignment'
                    ]
                },
                'data_modeling': {
                    'score': 84.6,
                    'status': 'Good',
                    'metrics': {
                        'model_consistency': 87.2,
                        'documentation_quality': 82.1,
                        'version_control': 89.3
                    },
                    'areas': [
                        'Conceptual Data Modeling',
                        'Logical Data Modeling',
                        'Physical Data Modeling',
                        'Data Dictionary Management'
                    ]
                },
                'data_quality': {
                    'score': 86.8,
                    'status': 'Good',
                    'metrics': {
                        'completeness_score': 89.4,
                        'accuracy_score': 84.7,
                        'consistency_score': 88.2,
                        'timeliness_score': 85.1
                    },
                    'areas': [
                        'Data Quality Assessment',
                        'Quality Monitoring',
                        'Issue Resolution',
                        'Quality Metrics'
                    ]
                },
                'data_security': {
                    'score': 93.4,
                    'status': 'Excellent',
                    'metrics': {
                        'access_control': 95.2,
                        'encryption_coverage': 91.8,
                        'audit_compliance': 94.7
                    },
                    'areas': [
                        'Data Classification',
                        'Access Management',
                        'Encryption Standards',
                        'Audit and Monitoring'
                    ]
                },
                'data_lifecycle': {
                    'score': 79.3,
                    'status': 'Needs Improvement',
                    'metrics': {
                        'retention_compliance': 82.5,
                        'archival_efficiency': 76.8,
                        'disposal_process': 81.2
                    },
                    'areas': [
                        'Data Retention Policies',
                        'Archival Procedures',
                        'Disposal Processes',
                        'Lifecycle Automation'
                    ]
                }
            },
            'sap_specific_metrics': {
                'equipment_master_data': {
                    'quality_score': 88.5,
                    'completeness': 91.2,
                    'accuracy': 86.7,
                    'consistency': 89.3
                },
                'functional_locations': {
                    'quality_score': 85.9,
                    'completeness': 88.1,
                    'accuracy': 84.2,
                    'consistency': 87.6
                },
                'maintenance_orders': {
                    'quality_score': 82.3,
                    'completeness': 85.7,
                    'accuracy': 80.1,
                    'consistency': 83.8
                }
            },
            'recommendations': [
                'Implement data lifecycle automation for improved retention compliance',
                'Enhance data modeling documentation standards',
                'Strengthen data stewardship program coverage',
                'Optimize archival procedures for better efficiency',
                'Expand data quality monitoring across all SAP modules'
            ],
            'dmbok2_maturity_assessment': {
                'overall_maturity': 'Level 3 (Defined)',
                'governance_maturity': 'Level 3 (Defined)',
                'architecture_maturity': 'Level 4 (Managed)',
                'quality_maturity': 'Level 3 (Defined)',
                'security_maturity': 'Level 4 (Managed)',
                'lifecycle_maturity': 'Level 2 (Repeatable)'
            }
        }
        
        if format_type == 'pdf':
            report_file = generate_pdf_report(report_data, 'data_management')
            return jsonify({
                'success': True,
                'download_url': f'/api/reports/download/{report_file}',
                'message': 'Data management report generated successfully'
            })
        else:
            return jsonify({
                'success': True,
                'data': report_data,
                'message': 'Data management data generated'
            })
            
    except Exception as e:
        logger.error(f"Error generating data management report: {str(e)}")
        return jsonify({'error': 'Failed to generate data management report'}), 500

class ComprehensiveDataContextProvider:
    """Provides comprehensive data context for AI agent including all data sources, calculations, and report mechanisms"""
    
    def __init__(self):
        self.reporter = DataQualityReporter()
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'database': os.getenv('DB_NAME', 'sap_data_quality'),
            'user': os.getenv('DB_USER', 'sap_user'),
            'password': os.getenv('DB_PASSWORD', 'your_db_password'),
            'port': 5432
        }
    
    def get_comprehensive_context(self, user_query: str) -> Dict[str, Any]:
        """Get comprehensive data context including all sources, calculations, and mechanisms"""
        try:
            context = {
                'query': user_query,
                'timestamp': datetime.utcnow().isoformat(),
                'data_sources': self._get_data_sources(),
                'calculations': self._get_calculations(),
                'report_mechanisms': self._get_report_mechanisms(),
                'data_subsets': self._get_data_subsets(),
                'metrics': self._get_metrics(),
                'trends': self._get_trends(),
                'relationships': self._get_data_relationships(),
                'quality_indicators': self._get_quality_indicators(),
                'system_status': self._get_system_status(),
                'vector_context': self._get_vector_context(user_query),
                'task_tracking': self._get_task_tracking_context(),
                'available_reports': self._get_available_reports(),
                'report_content': self._get_report_content_samples()
            }
            return context
        except Exception as e:
            logger.error(f"Failed to get comprehensive context: {e}")
            return {'error': str(e)}
    
    def _get_data_sources(self) -> Dict[str, Any]:
        """Get all data sources and their metadata"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            # Get all tables and their row counts
            cursor.execute("""
                SELECT 
                    table_name,
                    (SELECT COUNT(*) FROM information_schema.columns WHERE table_name = t.table_name) as column_count
                FROM information_schema.tables t
                WHERE table_schema = 'public'
                ORDER BY table_name
            """)
            
            tables = cursor.fetchall()
            data_sources = {}
            
            for table_name, column_count in tables:
                # Get row count for each table
                cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                row_count = cursor.fetchone()[0]
                
                # Get sample data structure
                cursor.execute(f"SELECT * FROM {table_name} LIMIT 1")
                sample_row = cursor.fetchone()
                
                data_sources[table_name] = {
                    'row_count': row_count,
                    'column_count': column_count,
                    'has_data': row_count > 0,
                    'last_updated': self._get_table_last_updated(table_name, cursor)
                }
            
            cursor.close()
            conn.close()
            
            return data_sources
            
        except Exception as e:
            logger.error(f"Failed to get data sources: {e}")
            return {}
    
    def _get_calculations(self) -> Dict[str, Any]:
        """Get all calculation methods and formulas"""
        return {
            'data_quality_score': {
                'formula': 'SUM(completeness + accuracy + consistency + timeliness) / 4',
                'components': ['completeness', 'accuracy', 'consistency', 'timeliness'],
                'weight': 0.25
            },
            'risk_score': {
                'formula': 'impact * probability * detection_difficulty',
                'components': ['impact', 'probability', 'detection_difficulty'],
                'scale': '1-10'
            },
            'performance_metrics': {
                'throughput': 'records_processed / time_period',
                'error_rate': 'failed_validations / total_validations',
                'response_time': 'average_processing_time'
            },
            'trend_calculations': {
                'moving_average': 'SUM(values) / window_size',
                'growth_rate': '(current_value - previous_value) / previous_value * 100',
                'volatility': 'standard_deviation / mean'
            }
        }
    
    def _get_report_mechanisms(self) -> Dict[str, Any]:
        """Get all report generation mechanisms and templates"""
        return {
            'report_types': {
                'executive_summary': {
                    'template': 'executive_report.html',
                    'metrics': ['kpi_dashboard', 'trends', 'risks', 'recommendations'],
                    'format': ['pdf', 'html']
                },
                'data_quality': {
                    'template': 'data_quality_report.html',
                    'metrics': ['validation_summary', 'issues', 'trends', 'remediation'],
                    'format': ['pdf', 'html']
                },
                'risk_assessment': {
                    'template': 'risk_assessment_report.html',
                    'metrics': ['risk_matrix', 'mitigation_plans', 'compliance'],
                    'format': ['pdf', 'html']
                },
                'system_health': {
                    'template': 'system_health_report.html',
                    'metrics': ['performance', 'availability', 'errors', 'capacity'],
                    'format': ['pdf', 'html']
                },
                'governance': {
                    'template': 'governance_compliance_report.html',
                    'metrics': ['policies', 'compliance', 'audit_trails'],
                    'format': ['pdf', 'html']
                }
            },
            'generation_methods': {
                'pdf': 'reportlab',
                'html': 'jinja2_templates',
                'excel': 'openpyxl',
                'csv': 'pandas'
            },
            'scheduling': {
                'frequency': ['daily', 'weekly', 'monthly', 'quarterly'],
                'automation': 'cron_jobs',
                'distribution': ['email', 'dashboard', 'api']
            }
        }
    
    def _get_data_subsets(self) -> Dict[str, Any]:
        """Get data subsets and filtering mechanisms"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            subsets = {}
            
            # Get task subsets with overdue detection
            cursor.execute("""
                SELECT 
                    status,
                    COUNT(*) as count,
                    COUNT(CASE WHEN due_date < CURRENT_DATE AND status != 'completed' THEN 1 END) as overdue_count,
                    COUNT(CASE WHEN due_date BETWEEN CURRENT_DATE AND CURRENT_DATE + INTERVAL '7 days' AND status != 'completed' THEN 1 END) as due_soon_count
                FROM tasks
                GROUP BY status
            """)
            task_results = cursor.fetchall()
            task_subsets = {}
            overdue_tasks = 0
            due_soon_tasks = 0
            
            for status, count, overdue, due_soon in task_results:
                task_subsets[status] = count
                overdue_tasks += overdue
                due_soon_tasks += due_soon
            
            # Add overdue tracking
            task_subsets['overdue'] = overdue_tasks
            task_subsets['due_soon'] = due_soon_tasks
            
            # Get risk subsets
            cursor.execute("""
                SELECT risk_level, COUNT(*) as count
                FROM risk_assessments
                GROUP BY risk_level
            """)
            risk_subsets = dict(cursor.fetchall())
            
            # Get quality metric subsets
            cursor.execute("""
                SELECT 
                    CASE 
                        WHEN current_value >= 90 THEN 'Excellent'
                        WHEN current_value >= 80 THEN 'Good'
                        WHEN current_value >= 70 THEN 'Fair'
                        ELSE 'Poor'
                    END as quality_level,
                    COUNT(*) as count
                FROM data_quality_metrics
                GROUP BY quality_level
            """)
            quality_subsets = dict(cursor.fetchall())
            
            # Get time-based subsets
            cursor.execute("""
                SELECT 
                    DATE(created_at) as date,
                    COUNT(*) as count
                FROM tasks
                WHERE created_at >= CURRENT_DATE - INTERVAL '30 days'
                GROUP BY DATE(created_at)
                ORDER BY date DESC
                LIMIT 10
            """)
            time_subsets = dict(cursor.fetchall())
            
            cursor.close()
            conn.close()
            
            return {
                'task_subsets': task_subsets,
                'risk_subsets': risk_subsets,
                'quality_subsets': quality_subsets,
                'time_subsets': time_subsets,
                'filtering_options': {
                    'date_range': ['last_7_days', 'last_30_days', 'last_90_days', 'custom'],
                    'status_filter': ['all', 'active', 'completed', 'failed'],
                    'priority_filter': ['high', 'medium', 'low'],
                    'category_filter': ['data_quality', 'system_health', 'security', 'compliance']
                }
            }
            
        except Exception as e:
            logger.error(f"Failed to get data subsets: {e}")
            return {}
    
    def _get_metrics(self) -> Dict[str, Any]:
        """Get all available metrics and their definitions"""
        return {
            'data_quality_metrics': {
                'completeness': 'Percentage of non-null values',
                'accuracy': 'Percentage of correct values',
                'consistency': 'Percentage of values following rules',
                'timeliness': 'Percentage of data updated within SLA',
                'uniqueness': 'Percentage of unique values',
                'validity': 'Percentage of values in expected format'
            },
            'performance_metrics': {
                'throughput': 'Records processed per second',
                'latency': 'Average response time',
                'error_rate': 'Percentage of failed operations',
                'availability': 'Percentage of uptime',
                'capacity_utilization': 'Percentage of resource usage'
            },
            'business_metrics': {
                'data_value_score': 'Monetary value of data assets',
                'compliance_score': 'Percentage of regulatory compliance',
                'risk_exposure': 'Total risk score across all assets',
                'efficiency_gain': 'Time saved through automation'
            }
        }
    
    def _get_trends(self) -> Dict[str, Any]:
        """Get trend analysis and patterns"""
        try:
            # Get quality trends
            quality_trends = self.reporter.get_quality_trends(days=30)
            
            # Get issue trends
            recent_issues = self.reporter.get_recent_issues(limit=100)
            issue_trends = self._analyze_issue_trends(recent_issues)
            
            return {
                'quality_trends': quality_trends,
                'issue_trends': issue_trends,
                'performance_trends': {
                    'response_time': 'Decreasing trend over last 30 days',
                    'error_rate': 'Stable at 2.3%',
                    'throughput': 'Increasing by 15% monthly'
                },
                'seasonal_patterns': {
                    'peak_hours': '9:00 AM - 11:00 AM',
                    'low_activity': '2:00 AM - 4:00 AM',
                    'weekly_pattern': 'Monday highest, Sunday lowest'
                }
            }
            
        except Exception as e:
            logger.error(f"Failed to get trends: {e}")
            return {}
    
    def _get_data_relationships(self) -> Dict[str, Any]:
        """Get data relationships and dependencies"""
        return {
            'entity_relationships': {
                'tasks': ['risk_assessments', 'data_quality_metrics'],
                'risk_assessments': ['tasks', 'system_health'],
                'data_quality_metrics': ['tasks', 'validation_rules'],
                'system_health': ['risk_assessments', 'performance_metrics']
            },
            'data_flows': {
                'ingestion': 'raw_data -> validation -> quality_check -> storage',
                'processing': 'storage -> transformation -> enrichment -> output',
                'reporting': 'processed_data -> aggregation -> visualization -> distribution'
            },
            'dependencies': {
                'critical_path': ['data_ingestion', 'validation', 'quality_assessment'],
                'optional_paths': ['enrichment', 'archival', 'backup'],
                'failure_points': ['network_connectivity', 'database_availability', 'validation_rules']
            }
        }
    
    def _get_quality_indicators(self) -> Dict[str, Any]:
        """Get quality indicators and thresholds"""
        return {
            'thresholds': {
                'excellent': {'min': 90, 'color': 'green'},
                'good': {'min': 80, 'max': 89, 'color': 'blue'},
                'fair': {'min': 70, 'max': 79, 'color': 'yellow'},
                'poor': {'max': 69, 'color': 'red'}
            },
            'indicators': {
                'data_freshness': 'Time since last update',
                'completeness_rate': 'Percentage of complete records',
                'accuracy_score': 'Percentage of accurate data',
                'consistency_level': 'Percentage of consistent data',
                'timeliness_metric': 'Percentage of on-time data'
            },
            'alerts': {
                'critical': 'Quality score < 70%',
                'warning': 'Quality score < 80%',
                'info': 'Quality score < 90%'
            }
        }
    
    def _get_system_status(self) -> Dict[str, Any]:
        """Get current system status and health"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM system_health")
            total_components = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM system_health WHERE status = 'healthy'")
            healthy_components = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM system_health WHERE status = 'warning'")
            warning_components = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM system_health WHERE status = 'critical'")
            critical_components = cursor.fetchone()[0]
            
            cursor.close()
            conn.close()
            
            return {
                'overall_status': 'healthy' if critical_components == 0 else 'warning',
                'component_count': total_components,
                'healthy_components': healthy_components,
                'warning_components': warning_components,
                'critical_components': critical_components,
                'health_percentage': (healthy_components / total_components * 100) if total_components > 0 else 0
            }
            
        except Exception as e:
            logger.error(f"Failed to get system status: {e}")
            return {}
    
    def _get_vector_context(self, query: str) -> List[Dict[str, Any]]:
        """Get vector search context for the query"""
        try:
            # Get vector search results
            vector_results = vector_service.get_ai_context(query, max_results=5)
            
            # If query mentions overdue or tasks, add specific overdue task context
            if any(keyword in query.lower() for keyword in ['overdue', 'task', 'due', 'tracking']):
                overdue_context = self._get_overdue_task_context()
                if overdue_context:
                    vector_results.extend(overdue_context)
            
            # If query mentions reports, add report context
            if any(keyword in query.lower() for keyword in ['report', 'reports', 'summary', 'dashboard', 'analysis']):
                report_context = self._get_report_context(query)
                if report_context:
                    vector_results.extend(report_context)
            
            return vector_results
        except Exception as e:
            logger.error(f"Failed to get vector context: {e}")
            return []
    
    def _get_overdue_task_context(self) -> List[Dict[str, Any]]:
        """Get specific context for overdue task tracking"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            # Get overdue tasks
            cursor.execute("""
                SELECT 
                    id, title, description, status, due_date, priority,
                    CASE 
                        WHEN due_date < CURRENT_DATE THEN 'overdue'
                        WHEN due_date BETWEEN CURRENT_DATE AND CURRENT_DATE + INTERVAL '7 days' THEN 'due_soon'
                        ELSE 'on_track'
                    END as urgency_level
                FROM tasks 
                WHERE due_date < CURRENT_DATE + INTERVAL '7 days' 
                AND status != 'completed'
                ORDER BY due_date ASC
                LIMIT 10
            """)
            
            overdue_tasks = cursor.fetchall()
            context_items = []
            
            for task_id, title, description, status, due_date, priority, urgency in overdue_tasks:
                context_items.append({
                    'content_text': f"Task: {title} - Status: {status} - Due: {due_date} - Priority: {priority} - Urgency: {urgency}",
                    'data_type': 'task',
                    'data_id': task_id,
                    'similarity': 0.9,
                    'metadata': {
                        'title': title,
                        'status': status,
                        'due_date': due_date.isoformat() if due_date else None,
                        'priority': priority,
                        'urgency_level': urgency
                    }
                })
            
            cursor.close()
            conn.close()
            
            return context_items
            
        except Exception as e:
            logger.error(f"Failed to get overdue task context: {e}")
            return []
    
    def _get_task_tracking_context(self) -> Dict[str, Any]:
        """Get comprehensive task tracking context including overdue mechanisms"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            # Get task tracking summary
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_tasks,
                    COUNT(CASE WHEN status = 'active' THEN 1 END) as active_tasks,
                    COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_tasks,
                    COUNT(CASE WHEN due_date < CURRENT_DATE AND status != 'completed' THEN 1 END) as overdue_tasks,
                    COUNT(CASE WHEN due_date BETWEEN CURRENT_DATE AND CURRENT_DATE + INTERVAL '7 days' AND status != 'completed' THEN 1 END) as due_soon_tasks,
                    COUNT(CASE WHEN priority = 'high' THEN 1 END) as high_priority_tasks,
                    AVG(CASE WHEN due_date IS NOT NULL THEN EXTRACT(DAY FROM (due_date - created_at)) END) as avg_days_to_deadline
                FROM tasks
            """)
            
            tracking_summary = cursor.fetchone()
            
            # Get overdue task details
            cursor.execute("""
                SELECT 
                    id, title, description, status, due_date, priority, created_at,
                    EXTRACT(DAY FROM (CURRENT_DATE - due_date)) as days_overdue
                FROM tasks 
                WHERE due_date < CURRENT_DATE AND status != 'completed'
                ORDER BY due_date ASC
                LIMIT 5
            """)
            
            overdue_details = cursor.fetchall()
            
            cursor.close()
            conn.close()
            
            return {
                'tracking_summary': {
                    'total_tasks': tracking_summary[0] if tracking_summary else 0,
                    'active_tasks': tracking_summary[1] if tracking_summary else 0,
                    'completed_tasks': tracking_summary[2] if tracking_summary else 0,
                    'overdue_tasks': tracking_summary[3] if tracking_summary else 0,
                    'due_soon_tasks': tracking_summary[4] if tracking_summary else 0,
                    'high_priority_tasks': tracking_summary[5] if tracking_summary else 0,
                    'avg_days_to_deadline': float(tracking_summary[6]) if tracking_summary and tracking_summary[6] else 0
                },
                'overdue_details': [
                    {
                        'id': task[0],
                        'title': task[1],
                        'description': task[2],
                        'status': task[3],
                        'due_date': task[4].isoformat() if task[4] else None,
                        'priority': task[4],
                        'days_overdue': int(task[7]) if task[7] else 0
                    }
                    for task in overdue_details
                ],
                'tracking_mechanisms': {
                    'overdue_detection': 'Automatic detection of tasks past due date',
                    'priority_tracking': 'High, medium, low priority classification',
                    'urgency_levels': ['overdue', 'due_soon', 'on_track'],
                    'alert_system': 'Notifications for overdue and due-soon tasks',
                    'reporting': 'Task management reports with overdue analysis'
                }
            }
            
        except Exception as e:
            logger.error(f"Failed to get task tracking context: {e}")
            return {}
    
    def _get_available_reports(self) -> Dict[str, Any]:
        """Get all available reports and their metadata"""
        return {
            'executive_reports': {
                'executive_summary': {
                    'description': 'High-level executive summary with KPIs and trends',
                    'metrics': ['overall_health', 'key_risks', 'performance_trends'],
                    'format': ['pdf', 'html'],
                    'frequency': 'weekly'
                },
                'kpi_dashboard': {
                    'description': 'Comprehensive KPI dashboard with performance metrics',
                    'metrics': ['data_quality_score', 'system_performance', 'risk_metrics'],
                    'format': ['pdf', 'html'],
                    'frequency': 'daily'
                }
            },
            'data_quality_reports': {
                'data_quality_analysis': {
                    'description': 'Detailed data quality analysis with validation results',
                    'metrics': ['completeness', 'accuracy', 'consistency', 'timeliness'],
                    'format': ['pdf', 'html'],
                    'frequency': 'daily'
                },
                'validation_rules': {
                    'description': 'Validation rules performance and compliance',
                    'metrics': ['rule_performance', 'compliance_rate', 'error_analysis'],
                    'format': ['pdf', 'html'],
                    'frequency': 'weekly'
                }
            },
            'risk_reports': {
                'risk_assessment': {
                    'description': 'Comprehensive risk assessment and mitigation plans',
                    'metrics': ['risk_matrix', 'mitigation_status', 'compliance_score'],
                    'format': ['pdf', 'html'],
                    'frequency': 'monthly'
                },
                'risk_matrix': {
                    'description': 'Risk matrix with impact and probability analysis',
                    'metrics': ['risk_levels', 'impact_analysis', 'probability_assessment'],
                    'format': ['pdf', 'html'],
                    'frequency': 'weekly'
                }
            },
            'system_reports': {
                'system_health': {
                    'description': 'System health and performance monitoring',
                    'metrics': ['availability', 'performance', 'error_rates'],
                    'format': ['pdf', 'html'],
                    'frequency': 'daily'
                },
                'architecture_analysis': {
                    'description': 'Data architecture analysis using Hub and Spoke framework',
                    'metrics': ['integration_status', 'scalability', 'performance'],
                    'format': ['pdf', 'html'],
                    'frequency': 'monthly'
                }
            },
            'governance_reports': {
                'governance_compliance': {
                    'description': 'Governance and compliance framework analysis',
                    'metrics': ['compliance_score', 'policy_adherence', 'audit_results'],
                    'format': ['pdf', 'html'],
                    'frequency': 'quarterly'
                },
                'data_management': {
                    'description': 'Data management analysis using DMBOK2 framework',
                    'metrics': ['data_governance', 'data_quality', 'data_lifecycle'],
                    'format': ['pdf', 'html'],
                    'frequency': 'monthly'
                }
            },
            'task_reports': {
                'task_management': {
                    'description': 'Task management with DevOps and Agile frameworks',
                    'metrics': ['task_status', 'overdue_tasks', 'completion_rate'],
                    'format': ['pdf', 'html'],
                    'frequency': 'daily'
                },
                'workflow_analysis': {
                    'description': 'Workflow analysis and process optimization',
                    'metrics': ['process_efficiency', 'bottlenecks', 'optimization_opportunities'],
                    'format': ['pdf', 'html'],
                    'frequency': 'weekly'
                }
            },
            'specialized_reports': {
                'data_lineage': {
                    'description': 'Data lineage and traceability analysis',
                    'metrics': ['data_flow', 'dependencies', 'impact_analysis'],
                    'format': ['pdf', 'html'],
                    'frequency': 'monthly'
                },
                'csuite_reports': {
                    'description': 'C-Suite focused reports for executive decision making',
                    'metrics': ['strategic_metrics', 'business_impact', 'recommendations'],
                    'format': ['pdf', 'html'],
                    'frequency': 'quarterly'
                }
            }
        }
    
    def _get_report_content_samples(self) -> Dict[str, Any]:
        """Get sample content from various reports for context"""
        return {
            'executive_summary_sample': {
                'overall_health': 'System operating at 94% efficiency',
                'key_risks': '3 high-priority risks identified',
                'performance_trends': '15% improvement in data quality over last quarter',
                'recommendations': 'Focus on overdue task resolution and system optimization'
            },
            'data_quality_sample': {
                'completeness_score': '87%',
                'accuracy_score': '92%',
                'consistency_score': '89%',
                'timeliness_score': '94%',
                'overall_quality': '90.5%'
            },
            'risk_assessment_sample': {
                'high_risk_items': 3,
                'medium_risk_items': 12,
                'low_risk_items': 25,
                'mitigation_progress': '78% of high-risk items addressed'
            },
            'task_management_sample': {
                'total_tasks': 150,
                'completed_tasks': 120,
                'overdue_tasks': 8,
                'due_soon_tasks': 15,
                'completion_rate': '80%'
            },
            'system_health_sample': {
                'availability': '99.2%',
                'response_time': '245ms average',
                'error_rate': '0.8%',
                'capacity_utilization': '67%'
            },
            'governance_sample': {
                'compliance_score': '94%',
                'policy_adherence': '91%',
                'audit_status': 'All critical controls in place',
                'data_protection': 'Fully compliant with regulations'
            }
        }
    
    def _get_table_last_updated(self, table_name: str, cursor) -> str:
        """Get last updated timestamp for a table"""
        try:
            # Try to get updated_at column if it exists
            cursor.execute(f"""
                SELECT MAX(updated_at) 
                FROM {table_name} 
                WHERE updated_at IS NOT NULL
            """)
            result = cursor.fetchone()
            return result[0].isoformat() if result and result[0] else 'Unknown'
        except:
            return 'Unknown'
    
    def _analyze_issue_trends(self, issues: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze trends in issues"""
        if not issues:
            return {}
        
        # Group by issue type
        issue_types = {}
        for issue in issues:
            issue_type = issue.get('issue_type', 'unknown')
            if issue_type not in issue_types:
                issue_types[issue_type] = 0
            issue_types[issue_type] += 1
        
        # Get top issues
        top_issues = sorted(issue_types.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return {
            'total_issues': len(issues),
            'issue_types': issue_types,
            'top_issues': top_issues,
            'trend': 'increasing' if len(issues) > 50 else 'stable'
        }
    
    def _get_report_context(self, query: str) -> List[Dict[str, Any]]:
        """Get specific context for reports based on query"""
        try:
            available_reports = self._get_available_reports()
            report_content = self._get_report_content_samples()
            
            context_items = []
            
            # Add executive reports context
            if any(keyword in query.lower() for keyword in ['executive', 'summary', 'kpi', 'dashboard']):
                for report_name, report_info in available_reports.get('executive_reports', {}).items():
                    context_items.append({
                        'content_text': f"Executive Report: {report_name} - {report_info['description']} - Metrics: {', '.join(report_info['metrics'])}",
                        'data_type': 'report',
                        'data_id': hash(report_name),
                        'similarity': 0.9,
                        'metadata': {
                            'report_type': 'executive',
                            'report_name': report_name,
                            'description': report_info['description'],
                            'metrics': report_info['metrics'],
                            'format': report_info['format']
                        }
                    })
            
            # Add data quality reports context
            if any(keyword in query.lower() for keyword in ['quality', 'data', 'validation', 'completeness']):
                for report_name, report_info in available_reports.get('data_quality_reports', {}).items():
                    context_items.append({
                        'content_text': f"Data Quality Report: {report_name} - {report_info['description']} - Metrics: {', '.join(report_info['metrics'])}",
                        'data_type': 'report',
                        'data_id': hash(report_name),
                        'similarity': 0.9,
                        'metadata': {
                            'report_type': 'data_quality',
                            'report_name': report_name,
                            'description': report_info['description'],
                            'metrics': report_info['metrics']
                        }
                    })
            
            # Add risk reports context
            if any(keyword in query.lower() for keyword in ['risk', 'assessment', 'matrix', 'mitigation']):
                for report_name, report_info in available_reports.get('risk_reports', {}).items():
                    context_items.append({
                        'content_text': f"Risk Report: {report_name} - {report_info['description']} - Metrics: {', '.join(report_info['metrics'])}",
                        'data_type': 'report',
                        'data_id': hash(report_name),
                        'similarity': 0.9,
                        'metadata': {
                            'report_type': 'risk',
                            'report_name': report_name,
                            'description': report_info['description'],
                            'metrics': report_info['metrics']
                        }
                    })
            
            # Add system reports context
            if any(keyword in query.lower() for keyword in ['system', 'health', 'architecture', 'performance']):
                for report_name, report_info in available_reports.get('system_reports', {}).items():
                    context_items.append({
                        'content_text': f"System Report: {report_name} - {report_info['description']} - Metrics: {', '.join(report_info['metrics'])}",
                        'data_type': 'report',
                        'data_id': hash(report_name),
                        'similarity': 0.9,
                        'metadata': {
                            'report_type': 'system',
                            'report_name': report_name,
                            'description': report_info['description'],
                            'metrics': report_info['metrics']
                        }
                    })
            
            # Add governance reports context
            if any(keyword in query.lower() for keyword in ['governance', 'compliance', 'policy', 'audit']):
                for report_name, report_info in available_reports.get('governance_reports', {}).items():
                    context_items.append({
                        'content_text': f"Governance Report: {report_name} - {report_info['description']} - Metrics: {', '.join(report_info['metrics'])}",
                        'data_type': 'report',
                        'data_id': hash(report_name),
                        'similarity': 0.9,
                        'metadata': {
                            'report_type': 'governance',
                            'report_name': report_name,
                            'description': report_info['description'],
                            'metrics': report_info['metrics']
                        }
                    })
            
            # Add sample content context
            for sample_name, sample_data in report_content.items():
                if isinstance(sample_data, dict):
                    content_summary = f"Report Sample: {sample_name} - {', '.join([f'{k}: {v}' for k, v in sample_data.items()])}"
                    context_items.append({
                        'content_text': content_summary,
                        'data_type': 'report_sample',
                        'data_id': hash(sample_name),
                        'similarity': 0.8,
                        'metadata': {
                            'sample_name': sample_name,
                            'sample_data': sample_data
                        }
                    })
            
            return context_items
            
        except Exception as e:
            logger.error(f"Failed to get report context: {e}")
            return []
    
    def _get_task_tracking_context(self) -> Dict[str, Any]:
        """Get comprehensive task tracking context including overdue mechanisms"""
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor()
            
            # Get task tracking summary
            cursor.execute("""
                SELECT 
                    COUNT(*) as total_tasks,
                    COUNT(CASE WHEN status = 'active' THEN 1 END) as active_tasks,
                    COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed_tasks,
                    COUNT(CASE WHEN due_date < CURRENT_DATE AND status != 'completed' THEN 1 END) as overdue_tasks,
                    COUNT(CASE WHEN due_date BETWEEN CURRENT_DATE AND CURRENT_DATE + INTERVAL '7 days' AND status != 'completed' THEN 1 END) as due_soon_tasks,
                    COUNT(CASE WHEN priority = 'high' THEN 1 END) as high_priority_tasks,
                    AVG(CASE WHEN due_date IS NOT NULL THEN EXTRACT(DAY FROM (due_date - created_at)) END) as avg_days_to_deadline
                FROM tasks
            """)
            
            tracking_summary = cursor.fetchone()
            
            # Get overdue task details
            cursor.execute("""
                SELECT 
                    id, title, description, status, due_date, priority, created_at,
                    EXTRACT(DAY FROM (CURRENT_DATE - due_date)) as days_overdue
                FROM tasks 
                WHERE due_date < CURRENT_DATE AND status != 'completed'
                ORDER BY due_date ASC
                LIMIT 5
            """)
            
            overdue_details = cursor.fetchall()
            
            cursor.close()
            conn.close()
            
            return {
                'tracking_summary': {
                    'total_tasks': tracking_summary[0] if tracking_summary else 0,
                    'active_tasks': tracking_summary[1] if tracking_summary else 0,
                    'completed_tasks': tracking_summary[2] if tracking_summary else 0,
                    'overdue_tasks': tracking_summary[3] if tracking_summary else 0,
                    'due_soon_tasks': tracking_summary[4] if tracking_summary else 0,
                    'high_priority_tasks': tracking_summary[5] if tracking_summary else 0,
                    'avg_days_to_deadline': float(tracking_summary[6]) if tracking_summary and tracking_summary[6] else 0
                },
                'overdue_details': [
                    {
                        'id': task[0],
                        'title': task[1],
                        'description': task[2],
                        'status': task[3],
                        'due_date': task[4].isoformat() if task[4] else None,
                        'priority': task[4],
                        'days_overdue': int(task[7]) if task[7] else 0
                    }
                    for task in overdue_details
                ],
                'tracking_mechanisms': {
                    'overdue_detection': 'Automatic detection of tasks past due date',
                    'priority_tracking': 'High, medium, low priority classification',
                    'urgency_levels': ['overdue', 'due_soon', 'on_track'],
                    'alert_system': 'Notifications for overdue and due-soon tasks',
                    'reporting': 'Task management reports with overdue analysis'
                }
            }
            
        except Exception as e:
            logger.error(f"Failed to get task tracking context: {e}")
            return {}

# Initialize AI Agent Manager
ai_agent_manager = None

def init_ai_agents():
    """Initialize AI agents"""
    global ai_agent_manager
    try:
        config = AgentConfig(
            validation_rule_enabled=True,
            ab_testing_enabled=True,
            missing_data_enabled=True,
            script_generation_enabled=True,
            schedule_interval_minutes=30,
            max_concurrent_agents=4
        )
        ai_agent_manager = AIAgentManager(config)
        
        # Also assign to app object for API access
        app.agent_manager = ai_agent_manager
        
        logger.info("AI agents initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize AI agents: {e}")

# Initialize AI agents when app starts
init_ai_agents()

# AI Agent Routes
@app.route('/api/ai-agents/status', methods=['GET'])
@login_required
@limiter.limit("10 per minute")
def get_agent_status():
    """Get status of all AI agents"""
    try:
        if ai_agent_manager:
            import asyncio
            status = asyncio.run(ai_agent_manager.get_agent_status())
            return jsonify({
                'success': True,
                'data': status,
                'timestamp': datetime.utcnow().isoformat()
            })
        else:
            return jsonify({
                'success': False,
                'message': 'AI agents not initialized',
                'timestamp': datetime.utcnow().isoformat()
            }), 500
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'timestamp': datetime.utcnow().isoformat()
        }), 500

@app.route('/api/ai-agents/workflow/<workflow_name>', methods=['POST'])
@login_required
@limiter.limit("5 per minute")
def execute_workflow(workflow_name):
    """Execute a specific workflow"""
    try:
        if not ai_agent_manager:
            return jsonify({
                'success': False,
                'message': 'AI agents not initialized',
                'timestamp': datetime.utcnow().isoformat()
            }), 500
        
        parameters = request.get_json() or {}
        import asyncio
        result = asyncio.run(ai_agent_manager.execute_workflow(workflow_name, parameters))
        return jsonify(result)
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'timestamp': datetime.utcnow().isoformat()
        }), 500

@app.route('/api/ai-agents/scripts', methods=['GET'])
@login_required
@limiter.limit("10 per minute")
def get_scripts():
    """Get all generated scripts from SQLite (tests.db reused or a new scripts table)"""
    try:
        import sqlite3
        items = []
        with sqlite3.connect('/app/data/tests.db') as conn:
            conn.row_factory = sqlite3.Row
            cur = conn.cursor()
            cur.execute("""
                CREATE TABLE IF NOT EXISTS scripts (
                    id TEXT PRIMARY KEY,
                    name TEXT,
                    description TEXT,
                    status TEXT,
                    created_at TEXT,
                    approved_at TEXT
                )
            """)
            cur.execute("SELECT id, name, description, status, created_at, approved_at FROM scripts ORDER BY created_at DESC")
            for row in cur.fetchall():
                items.append(dict(row))
        return jsonify({'success': True, 'data': items, 'timestamp': datetime.utcnow().isoformat()})
    except Exception as e:
        logger.error(f"AI scripts fetch failed: {e}")
        return jsonify({'success': False, 'message': str(e), 'timestamp': datetime.utcnow().isoformat()}), 500

@app.route('/api/ai-agents/scripts/<script_id>/approve', methods=['POST'])
@login_required
@limiter.limit("5 per minute")
def approve_script(script_id):
    """Approve a generated script (SQLite)"""
    try:
        import sqlite3
        with sqlite3.connect('/app/data/tests.db') as conn:
            cur = conn.cursor()
            cur.execute("UPDATE scripts SET status = 'Approved', approved_at = ? WHERE id = ?", (datetime.utcnow().isoformat(), script_id))
            conn.commit()
        return jsonify({'success': True, 'message': f'Script {script_id} approved successfully', 'timestamp': datetime.utcnow().isoformat()})
    except Exception as e:
        logger.error(f"Approve script failed: {e}")
        return jsonify({'success': False, 'message': str(e), 'timestamp': datetime.utcnow().isoformat()}), 500

@app.route('/api/ai-agents/rules', methods=['GET'])
@login_required
@limiter.limit("30 per minute")
def get_validation_rules():
    """Get all validation rules created by AI agents from SQLite rules.db"""
    try:
        import sqlite3
        rules = []
        with sqlite3.connect('/app/data/rules.db') as conn:
            conn.row_factory = sqlite3.Row
            cur = conn.cursor()
            cur.execute("SELECT id, name, description, sql_condition, severity, category, created_by, created_at, is_active FROM validation_rules ORDER BY created_at DESC")
            for row in cur.fetchall():
                rules.append({
                    'id': row['id'],
                    'name': row['name'],
                    'description': row['description'],
                    'sql_condition': row['sql_condition'],
                    'severity': row['severity'],
                    'category': row['category'],
                    'created_by': row['created_by'],
                    'created_at': row['created_at'],
                    'is_active': bool(row['is_active'])
                })
        logger.info(f"AI rules fetched: {len(rules)}")
        return jsonify({
            'success': True,
            'data': rules,
            'timestamp': datetime.utcnow().isoformat()
        })
    except Exception as e:
        logger.error(f"AI rules fetch failed: {e}")
        return jsonify({
            'success': False,
            'message': str(e),
            'timestamp': datetime.utcnow().isoformat()
        }), 500

@app.route('/api/ai-agents/tests', methods=['GET'])
@login_required
@limiter.limit("10 per minute")
def get_ab_tests():
    """Get all A/B tests from SQLite tests.db"""
    try:
        import sqlite3, json as pyjson
        tests = []
        with sqlite3.connect('/app/data/tests.db') as conn:
            conn.row_factory = sqlite3.Row
            cur = conn.cursor()
            cur.execute("""
                CREATE TABLE IF NOT EXISTS ab_tests (
                    id TEXT PRIMARY KEY,
                    name TEXT,
                    rule_a TEXT,
                    rule_b TEXT,
                    start_date TEXT,
                    end_date TEXT,
                    status TEXT,
                    metrics TEXT
                )
            """)
            cur.execute("SELECT id, name, rule_a, rule_b, start_date, end_date, status, metrics FROM ab_tests ORDER BY start_date DESC")
            for row in cur.fetchall():
                item = dict(row)
                # parse metrics/json fields if present
                if item.get('metrics'):
                    try:
                        item['metrics'] = pyjson.loads(item['metrics'])
                    except Exception:
                        pass
                if item.get('rule_a'):
                    try:
                        item['rule_a'] = pyjson.loads(item['rule_a'])
                    except Exception:
                        pass
                if item.get('rule_b'):
                    try:
                        item['rule_b'] = pyjson.loads(item['rule_b'])
                    except Exception:
                        pass
                tests.append(item)
        return jsonify({'success': True, 'data': tests, 'timestamp': datetime.utcnow().isoformat()})
    except Exception as e:
        logger.error(f"A/B tests fetch failed: {e}")
        return jsonify({'success': False, 'message': str(e), 'timestamp': datetime.utcnow().isoformat()}), 500

@app.route('/api/ai-agents/tasks', methods=['GET'])
@login_required
@limiter.limit("10 per minute")
def get_ai_tasks():
    """Get all tasks created by AI agents"""
    try:
        from ai_agents import TaskRepository
        import asyncio
        repo = TaskRepository()
        tasks = asyncio.run(repo.get_tasks())
        return jsonify({'success': True, 'data': tasks, 'timestamp': datetime.utcnow().isoformat()})
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'timestamp': datetime.utcnow().isoformat()
        }), 500

@app.route('/api/ai-agents/task-execution', methods=['POST'])
@login_required
@limiter.limit("10 per minute")
def execute_task_management():
    """Execute task management operations"""
    try:
        import asyncio
        data = request.get_json() or {}
        operation = data.get('operation', 'monitor')
        
        # Get the task execution agent
        agent_manager = getattr(app, 'agent_manager', None)
        if not agent_manager:
            return jsonify({
                'success': False,
                'message': 'Agent manager not initialized',
                'timestamp': datetime.utcnow().isoformat()
            }), 500
        
        # Execute the task management operation
        result = asyncio.run(agent_manager.agents['task_execution'].execute(data))
        
        return jsonify({
            'success': True,
            'data': result,
            'timestamp': datetime.utcnow().isoformat()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'timestamp': datetime.utcnow().isoformat()
        }), 500

@app.route('/api/ai-agents/task-execution/<task_id>', methods=['PUT'])
@login_required
@limiter.limit("20 per minute")
def update_task_status(task_id):
    """Update task status and completion"""
    try:
        import asyncio
        data = request.get_json() or {}
        status = data.get('status')
        completion_percentage = data.get('completion_percentage')
        
        if not status:
            return jsonify({
                'success': False,
                'message': 'Status is required',
                'timestamp': datetime.utcnow().isoformat()
            }), 400
        
        # Get the task execution agent
        agent_manager = getattr(app, 'agent_manager', None)
        if not agent_manager:
            return jsonify({
                'success': False,
                'message': 'Agent manager not initialized',
                'timestamp': datetime.utcnow().isoformat()
            }), 500
        
        # Update task status
        result = asyncio.run(agent_manager.agents['task_execution'].execute({
            'operation': 'update_status',
            'task_id': task_id,
            'status': status,
            'completion_percentage': completion_percentage
        }))
        
        return jsonify({
            'success': True,
            'data': result,
            'timestamp': datetime.utcnow().isoformat()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'timestamp': datetime.utcnow().isoformat()
        }), 500

# Tasks API (SQLite-backed)
@app.route('/api/tasks', methods=['GET', 'POST'])
@login_required
@limiter.limit("60 per hour")
def tasks_collection():
    try:
        from ai_agents import TaskRepository, Task
        import asyncio
        repo = TaskRepository()
        if request.method == 'GET':
            status = request.args.get('status')
            priority = request.args.get('priority')
            tasks = asyncio.run(repo.get_tasks(status=status, priority=priority))
            # Frontend expects a bare array
            return jsonify(tasks)
        else:
            payload = request.get_json() or {}
            title = payload.get('title')
            if not title:
                return jsonify({'error': 'title is required'}), 400
            description = payload.get('description', '')
            priority = payload.get('priority', 'Medium')
            task = Task(title=title, description=description, priority=priority)
            task.entity_type = payload.get('entity_type', task.entity_type)
            task.entity_id = payload.get('entity_id', task.entity_id)
            asyncio.run(repo.save_task(task))
            return jsonify({'id': task.id, 'title': task.title}), 201
    except Exception as e:
        logger.error(f"Tasks collection error: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/tasks/<task_id>', methods=['PUT', 'DELETE', 'GET'])
@login_required
@limiter.limit("60 per hour")
def task_item(task_id):
    try:
        from ai_agents import TaskRepository
        import asyncio, sqlite3
        repo = TaskRepository()
        if request.method == 'GET':
            tasks = asyncio.run(repo.get_tasks())
            task = next((t for t in tasks if t['id'] == task_id), None)
            if not task:
                return jsonify({'error': 'not found'}), 404
            return jsonify(task)
        elif request.method == 'PUT':
            data = request.get_json() or {}
            status = data.get('status')
            completion = data.get('completion_percentage')
            asyncio.run(repo.update_task_status(task_id, status or 'Open', completion))
            return jsonify({'id': task_id, 'status': status, 'completion_percentage': completion})
        else:  # DELETE
            # Direct delete since repository has no delete method yet
            with sqlite3.connect('/app/data/tasks.db') as conn:
                conn.execute("DELETE FROM tasks WHERE id = ?", (task_id,))
            return ('', 204)
    except Exception as e:
        logger.error(f"Task item error: {e}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080, debug=False) 